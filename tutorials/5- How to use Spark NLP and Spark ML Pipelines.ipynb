{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark NLP and Spark ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Topic Modeling\n",
    "\n",
    "`Spark-NLP`\n",
    "* DocumentAssembler\n",
    "* SentenceDetector\n",
    "* Tokenizer\n",
    "* Normalizer\n",
    "* POS tagger\n",
    "* Chunker\n",
    "* Finisher\n",
    "\n",
    "`Spark ML`\n",
    "* Hashing\n",
    "* TF-IDF\n",
    "* LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "2.2.0\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download some scientific sample from PubMed dataset:\n",
    "```\n",
    "wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Failed to set locale category LC_NUMERIC to en_FR.\n",
      "Warning: Failed to set locale category LC_TIME to en_FR.\n",
      "Warning: Failed to set locale category LC_COLLATE to en_FR.\n",
      "Warning: Failed to set locale category LC_MONETARY to en_FR.\n",
      "Warning: Failed to set locale category LC_MESSAGES to en_FR.\n",
      "--2019-09-10 15:25:20--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.186.5\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.186.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10484510 (10.0M) [text/csv]\n",
      "Saving to: ‘/tmp/pubmed-sample.csv’\n",
      "\n",
      "pubmed-sample.csv   100%[===================>]  10.00M  4.80MB/s    in 2.1s    \n",
      "\n",
      "2019-09-10 15:25:23 (4.80 MB/s) - ‘/tmp/pubmed-sample.csv’ saved [10484510/10484510]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubMedDF = spark.read\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(\"/tmp/pubmed-sample.csv\")\\\n",
    "                .filter(\"AB IS NOT null\")\\\n",
    "                .withColumn(\"text\", col(\"AB\"))\\\n",
    "                .drop(\"TI\", \"AB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|The human KCNJ9 (...|\n",
      "|BACKGROUND: At pr...|\n",
      "|OBJECTIVE: To inv...|\n",
      "|Combined EEG/fMRI...|\n",
      "|Kohlschutter synd...|\n",
      "|Statistical analy...|\n",
      "|The synthetic DOX...|\n",
      "|Our objective was...|\n",
      "|We conducted a ph...|\n",
      "|\"Monomeric sarcos...|\n",
      "|We presented the ...|\n",
      "|The literature de...|\n",
      "|A novel approach ...|\n",
      "|An HPLC-ESI-MS-MS...|\n",
      "|The localizing an...|\n",
      "|OBJECTIVE: To eva...|\n",
      "|For the construct...|\n",
      "|We report the res...|\n",
      "|Intraparenchymal ...|\n",
      "|It is known that ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pubMedDF.printSchema()\n",
    "pubMedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7537"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubMedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Spark NLP Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "posTagger = PerceptronModel.pretrained() \\\n",
    "  .setInputCols([\"sentence\", \"token\"])\n",
    "\n",
    "chunker = Chunker() \\\n",
    "    .setInputCols([\"sentence\", \"pos\"]) \\\n",
    "    .setOutputCol(\"chunk\") \\\n",
    "    .setRegexParsers([\"<NNP>+\", \"<DT>?<JJ>*<NN>\"])\n",
    "\n",
    "finisher = Finisher() \\\n",
    "  .setInputCols([\"chunk\"]) \\\n",
    "  .setIncludeMetadata(False)\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector, \n",
    "    tokenizer,\n",
    "    posTagger,\n",
    "    chunker,\n",
    "    finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlpPipelineDF = nlpPipeline.fit(pubMedDF).transform(pubMedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPark ML Pipeline\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"finished_chunk\", outputCol=\"features\", vocabSize=1000, minDF=10.0, minTF=10.0)\n",
    "idf = IDF(inputCol=\"features\", outputCol=\"idf\")\n",
    "lda = LDA(k=10, maxIter=5)\n",
    "### Let's create Spark-NLP Pipeline\n",
    "mlPipeline = Pipeline(stages=[\n",
    "    cv,\n",
    "    idf,\n",
    "    lda\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to train Spark ML Pipeline by using Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create Spark-NLP Pipeline\n",
    "mlModel = mlPipeline.fit(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlPipelineDF = mlModel.transform(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "|                text|      finished_chunk|    features|         idf|   topicDistribution|\n",
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "|The human KCNJ9 (...|[KCNJ9, Kir, GIRK...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|BACKGROUND: At pr...|[BACKGROUND, the ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To inv...|[OBJECTIVE, =9796...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Combined EEG/fMRI...|[Combined EEG/fMR...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Kohlschutter synd...|[Kohlschutter, sy...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Statistical analy...|[Statistical, ana...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The synthetic DOX...|[DOX-LNA, conjuga...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Our objective was...|[objective, blood...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We conducted a ph...|[II, a phase, stu...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|\"Monomeric sarcos...|[Monomeric, MSOX,...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We presented the ...|[Exorista, Mythim...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The literature de...|[The literature, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|A novel approach ...|[A novel, approac...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|An HPLC-ESI-MS-MS...|[HPLC-ESI-MS-MS, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The localizing an...|[The localizing, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To eva...|[OBJECTIVE, June,...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|For the construct...|[the construction...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We report the res...|[PNP, GSTO, Yaqui...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Intraparenchymal ...|[Intraparenchymal...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|It is known that ...|[Klinefelter's, s...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlPipelineDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = mlModel.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -19456.289390402628\n",
      "The upper bound on perplexity: 12.708222985240123\n"
     ]
    }
   ],
   "source": [
    "ll = ldaModel.logLikelihood(mlPipelineDF)\n",
    "lp = ldaModel.logPerplexity(mlPipelineDF)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+---------------+---------------------------------------------------------------------+\n",
      "|topic|termIndices    |termWeights                                                          |\n",
      "+-----+---------------+---------------------------------------------------------------------+\n",
      "|0    |[129, 85, 162] |[0.009857518024483591, 0.007910888626305495, 0.0013025172935866678]  |\n",
      "|1    |[300, 927, 770]|[0.007935607563269446, 0.0074662423167941964, 0.0013577441277888302] |\n",
      "|2    |[3, 6, 0]      |[0.042247589630979306, 0.02338549033457705, 0.021292477055820495]    |\n",
      "|3    |[19, 12, 645]  |[0.008850993650447876, 0.008838468891365777, 0.0013980774883356314]  |\n",
      "|4    |[22, 134, 57]  |[0.027669589971554293, 0.013629145818395184, 0.007339287603627411]   |\n",
      "|5    |[51, 537, 367] |[0.008808355396129218, 0.0075699921801503384, 0.0013106696237524754] |\n",
      "|6    |[774, 384, 332]|[0.009588666613626525, 0.008160356153952601, 0.007368502499050751]   |\n",
      "|7    |[1, 666, 615]  |[0.016949560024410427, 0.01229056899059046, 0.007786152311417697]    |\n",
      "|8    |[779, 923, 896]|[0.0013173962445838143, 0.0013063767493407376, 0.0013008081251997775]|\n",
      "|9    |[916, 613, 9]  |[0.012889147812499674, 0.0013497678857551094, 0.001263791079064674]  |\n",
      "+-----+---------------+---------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "ldaModel.describeTopics(3).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at out topics\n",
    "NOTE: More cleaning, filtering, playing around with `CountVectorizer`, and more iterations in `LDA` will result in better Topic Modelling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 1000 words):\n",
      "topic:  0\n",
      "----------\n",
      "dose\n",
      "glucose\n",
      "increase\n",
      "platelet\n",
      "length\n",
      "a combination\n",
      "side\n",
      "degradation\n",
      "ethanol\n",
      "conclusion\n",
      "reaction\n",
      "a patient\n",
      "performance\n",
      "myocardial\n",
      "PCR\n",
      "model\n",
      "Doppler\n",
      "safety\n",
      "epilepsy\n",
      "this review\n",
      "presentation\n",
      "electron\n",
      "health\n",
      "resistance\n",
      "prevalence\n",
      "AR\n",
      "MR\n",
      "neuronal\n",
      "course\n",
      "family\n",
      "transfer\n",
      "MS\n",
      "restriction\n",
      "matrix\n",
      "evaluation\n",
      "emission\n",
      "ability\n",
      "ischemia\n",
      "monitoring\n",
      "account\n",
      "CF\n",
      "implantation\n",
      "surgery\n",
      "acetate\n",
      "outcome\n",
      "the patient\n",
      "validity\n",
      "a reduction\n",
      "cortex\n",
      "correlation\n",
      "----------\n",
      "topic:  1\n",
      "----------\n",
      "cm\n",
      "DCs\n",
      "stimuli\n",
      "energy\n",
      "choice\n",
      "injection\n",
      "factor\n",
      "neck\n",
      "food\n",
      "Type\n",
      "the study\n",
      "gradient\n",
      "milk\n",
      "class\n",
      "ratio\n",
      "the method\n",
      "no significant difference\n",
      "animal\n",
      "IL-10\n",
      "accumulation\n",
      "kDa\n",
      "a variety\n",
      ">\n",
      "amount\n",
      "receptor\n",
      "The method\n",
      "pressure\n",
      "heat\n",
      "peptide\n",
      "hydrogen\n",
      "i.e\n",
      "HCV\n",
      "gender\n",
      "Data\n",
      "incidence\n",
      "Doppler\n",
      "utilization\n",
      "test\n",
      "adhesion\n",
      "virus\n",
      "model\n",
      "patientswith\n",
      "enhancement\n",
      "location\n",
      "the type\n",
      "sperm\n",
      "outcome\n",
      "the range\n",
      "the frequency\n",
      "secretion\n",
      "----------\n",
      "topic:  2\n",
      "----------\n",
      "group\n",
      "+/\n",
      ").\n",
      "P\n",
      "HF\n",
      "diabetes\n",
      "intensity\n",
      "shock\n",
      "the rate\n",
      "the regulation\n",
      "gene\n",
      "posterior\n",
      "extracellular\n",
      "a role\n",
      "the surface\n",
      "interference\n",
      "care\n",
      "cannot\n",
      "the proportion\n",
      "DESIGN\n",
      "trauma\n",
      "preparation\n",
      "the rat\n",
      "the prevalence\n",
      "methylation\n",
      "exhibit\n",
      "this work\n",
      "the brain\n",
      "recurrence\n",
      "body\n",
      "effectiveness\n",
      "the efficacy\n",
      "thedevelopment\n",
      "obese\n",
      "class\n",
      "a series\n",
      "ventricular\n",
      "MAP\n",
      "novel\n",
      "N\n",
      "fever\n",
      "the use\n",
      "activity\n",
      "channel\n",
      "space\n",
      "healthcare\n",
      "PD\n",
      "+\n",
      "cleavage\n",
      "surface\n",
      "----------\n",
      "topic:  3\n",
      "----------\n",
      "p\n",
      "<\n",
      "trauma\n",
      "tyrosine\n",
      "involvement\n",
      "change\n",
      "home\n",
      "organ\n",
      "severity\n",
      "dopamine\n",
      "period\n",
      "migration\n",
      "a combination\n",
      "toxicity\n",
      "application\n",
      "test\n",
      "regulation\n",
      "antibody\n",
      "a mean\n",
      "sleep\n",
      "The effect\n",
      "damage\n",
      "thepresence\n",
      "the patient\n",
      "cycle\n",
      "target\n",
      "nM\n",
      "II\n",
      "method\n",
      "efficiency\n",
      "J\n",
      "radiation\n",
      "motion\n",
      "decrease\n",
      "mutant\n",
      "the activity\n",
      "contact\n",
      "ventricular\n",
      "HCC\n",
      "Gy\n",
      "a group\n",
      "the role\n",
      "theory\n",
      "survival\n",
      "AIM\n",
      "intake\n",
      "fluid\n",
      "fusion\n",
      "the study\n",
      "This article\n",
      "----------\n",
      "topic:  4\n",
      "----------\n",
      "C\n",
      "life\n",
      "CI\n",
      "blood\n",
      "maximum\n",
      "time\n",
      "serum\n",
      "stress\n",
      "the treatment\n",
      "velocity\n",
      "questionnaire\n",
      "proliferation\n",
      "X\n",
      "a total\n",
      "the regulation\n",
      "the majority\n",
      "the importance\n",
      "ability\n",
      "this method\n",
      "J\n",
      "kDa\n",
      "profile\n",
      "SC\n",
      "the concentration\n",
      "field\n",
      "this study\n",
      "assay\n",
      "RNA\n",
      "HR\n",
      "Type\n",
      "ELISA\n",
      "point\n",
      "dementia\n",
      "neuronal\n",
      "P<0.001\n",
      "The study\n",
      "respect\n",
      "movement\n",
      "associatedwith\n",
      "density\n",
      "testing\n",
      "the tumor\n",
      "the growth\n",
      "sleep\n",
      ")),\n",
      "inhibit\n",
      "task\n",
      "force\n",
      "IL-2\n",
      "literature\n",
      "----------\n",
      "topic:  5\n",
      "----------\n",
      "tumor\n",
      "ER\n",
      "necrosis\n",
      "stimuli\n",
      "mechanism\n",
      "the activity\n",
      "epithelium\n",
      "CT\n",
      "GSH\n",
      "nM\n",
      "viability\n",
      "loci\n",
      "review\n",
      "node\n",
      "a control\n",
      "the other hand\n",
      "selection\n",
      "IFN-gamma\n",
      "albumin\n",
      "plant\n",
      "case\n",
      "mice\n",
      "bp\n",
      "AIM\n",
      "microM\n",
      "the level\n",
      "leukemia\n",
      "staff\n",
      "thyroid\n",
      "soil\n",
      "nucleus\n",
      "the existence\n",
      "processing\n",
      "proliferation\n",
      "lung\n",
      "affinity\n",
      "interval\n",
      "wall\n",
      "HF\n",
      "immunohistochemistry\n",
      "no significant difference\n",
      "E\n",
      "analysis\n",
      "aggregation\n",
      "the lack\n",
      "The purpose\n",
      "i\n",
      "search\n",
      "home\n",
      "resistance\n",
      "----------\n",
      "topic:  6\n",
      "----------\n",
      "cent\n",
      "HIV-1\n",
      "history\n",
      "%\n",
      "P<0.001\n",
      "cohort\n",
      "response\n",
      "health\n",
      "lipid\n",
      "lead\n",
      "matrix\n",
      "synthesis\n",
      "survival\n",
      "the onset\n",
      "status\n",
      "image\n",
      "AA\n",
      "platelet\n",
      "curve\n",
      "The purpose\n",
      "exercise\n",
      "release\n",
      "brain\n",
      "scale\n",
      "analysis\n",
      "recognition\n",
      "cholesterol\n",
      "a series\n",
      "PD\n",
      "rate\n",
      "signal\n",
      "drug\n",
      "calcium\n",
      "the mean\n",
      "management\n",
      "tomography\n",
      "the \"\"\n",
      "rest\n",
      "test\n",
      "trial\n",
      "a wide range\n",
      "initiation\n",
      "the skin\n",
      "inthe\n",
      "aim\n",
      "degree\n",
      "program\n",
      "memory\n",
      "day\n",
      "the association\n",
      "----------\n",
      "topic:  7\n",
      "----------\n",
      "),\n",
      "max\n",
      "tube\n",
      "class\n",
      "change\n",
      "proximal\n",
      "pH\n",
      "behavior\n",
      "kinase\n",
      "The aim\n",
      "the management\n",
      "June\n",
      "content\n",
      "exercise\n",
      "the range\n",
      "median\n",
      "operation\n",
      "fever\n",
      "+/\n",
      "growth\n",
      "status\n",
      "contact\n",
      "account\n",
      "separation\n",
      "region\n",
      "exposure\n",
      "practice\n",
      "implantation\n",
      "RT-PCR\n",
      "OBJECTIVES\n",
      "regression\n",
      "albumin\n",
      "size\n",
      "electron\n",
      "the existence\n",
      "factor\n",
      "iron\n",
      "time\n",
      "serum\n",
      "height\n",
      "pregnancy\n",
      "J\n",
      "contrast\n",
      "enhancement\n",
      "half\n",
      "oxygen\n",
      "n\n",
      "phosphatase\n",
      "DNA\n",
      "day\n",
      "----------\n",
      "topic:  8\n",
      "----------\n",
      "DA\n",
      "the induction\n",
      "AA\n",
      "intervention\n",
      "median\n",
      "attention\n",
      "month\n",
      "core\n",
      "e.g\n",
      "alcohol\n",
      "GnRH\n",
      "component\n",
      "birth\n",
      "phase\n",
      "location\n",
      "place\n",
      "a range\n",
      "the management\n",
      "the maximum\n",
      "the plasma\n",
      "radiation\n",
      "involvement\n",
      "transplantation\n",
      "specificity\n",
      "conclusion\n",
      "tolerance\n",
      "control\n",
      "rise\n",
      "DC\n",
      "problem\n",
      "fluid\n",
      "Moreover\n",
      "understanding\n",
      "smoking\n",
      "surgery\n",
      "child\n",
      "a wide range\n",
      "spectroscopy\n",
      "N\n",
      "The study\n",
      "improvement\n",
      "examination\n",
      "training\n",
      "bladder\n",
      "association\n",
      "The purpose\n",
      "domain\n",
      "microm\n",
      "the importance\n",
      "AML\n",
      "----------\n",
      "topic:  9\n",
      "----------\n",
      "Cu\n",
      "the response\n",
      "analysis\n",
      "lymph\n",
      "cholesterol\n",
      "mechanism\n",
      "soil\n",
      "energy\n",
      "research\n",
      "heart\n",
      "head\n",
      "a significant increase\n",
      "HF\n",
      "association\n",
      "a number\n",
      "the presence\n",
      "the type\n",
      "form\n",
      "receptor\n",
      "a group\n",
      "show\n",
      "inflammation\n",
      "design\n",
      "pressure\n",
      "vitamin\n",
      "review\n",
      "proximal\n",
      "aim\n",
      "strength\n",
      "life\n",
      "number\n",
      "the treatment\n",
      "United\n",
      "compliance\n",
      "the impact\n",
      "surface\n",
      "calcium\n",
      "storage\n",
      "GH\n",
      "transplantation\n",
      "leukemia\n",
      "posterior\n",
      "agent\n",
      "the reaction\n",
      "nucleus\n",
      "polymerase\n",
      "smooth muscle\n",
      "antibody\n",
      "nM\n",
      "respect\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "\n",
    "topics = ldaModel.describeTopics(50)\n",
    "topics_rdd = topics.rdd\n",
    "\n",
    "vocab = mlModel.stages[0].vocabulary\n",
    "\n",
    "topics_words = topics_rdd\\\n",
    "       .map(lambda row: row['termIndices'])\\\n",
    "       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "       .collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: \", idx)\n",
    "    print(\"----------\")\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"----------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
