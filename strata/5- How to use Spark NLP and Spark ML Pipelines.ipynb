{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark NLP and Spark ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Topic Modeling\n",
    "\n",
    "`Spark-NLP`\n",
    "* DocumentAssembler\n",
    "* SentenceDetector\n",
    "* Tokenizer\n",
    "* Normalizer\n",
    "* POS tagger\n",
    "* Chunker\n",
    "* Finisher\n",
    "\n",
    "`Spark ML`\n",
    "* Hashing\n",
    "* TF-IDF\n",
    "* LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download some scientific sample from PubMed dataset:\n",
    "```\n",
    "wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubMedDF = spark.read\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(\"/tmp/pubmed-sample.csv\")\\\n",
    "                .filter(\"AB IS NOT null\")\\\n",
    "                .withColumn(\"text\", col(\"AB\"))\\\n",
    "                .drop(\"TI\", \"AB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|The human KCNJ9 (...|\n",
      "|BACKGROUND: At pr...|\n",
      "|OBJECTIVE: To inv...|\n",
      "|Combined EEG/fMRI...|\n",
      "|Kohlschutter synd...|\n",
      "|Statistical analy...|\n",
      "|The synthetic DOX...|\n",
      "|Our objective was...|\n",
      "|We conducted a ph...|\n",
      "|\"Monomeric sarcos...|\n",
      "|We presented the ...|\n",
      "|The literature de...|\n",
      "|A novel approach ...|\n",
      "|An HPLC-ESI-MS-MS...|\n",
      "|The localizing an...|\n",
      "|OBJECTIVE: To eva...|\n",
      "|For the construct...|\n",
      "|We report the res...|\n",
      "|Intraparenchymal ...|\n",
      "|It is known that ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pubMedDF.printSchema()\n",
    "pubMedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7537"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubMedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 4.23 ms, total: 18.3 ms\n",
      "Wall time: 48.3 ms\n"
     ]
    }
   ],
   "source": [
    "# Spark NLP Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "posTagger = PerceptronModel.pretrained() \\\n",
    "  .setInputCols([\"sentence\", \"token\"])\n",
    "\n",
    "chunker = Chunker() \\\n",
    "    .setInputCols([\"sentence\", \"pos\"]) \\\n",
    "    .setOutputCol(\"chunk\") \\\n",
    "    .setRegexParsers([\"<NNP>+\", \"<DT>?<JJ>*<NN>\"])\n",
    "\n",
    "finisher = Finisher() \\\n",
    "  .setInputCols([\"chunk\"]) \\\n",
    "  .setIncludeMetadata(False)\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector, \n",
    "    tokenizer,\n",
    "    posTagger,\n",
    "    chunker,\n",
    "    finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 ms, sys: 6.6 ms, total: 24.7 ms\n",
      "Wall time: 450 ms\n"
     ]
    }
   ],
   "source": [
    "nlpPipelineDF = nlpPipeline.fit(pubMedDF).transform(pubMedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.64 ms, sys: 855 Âµs, total: 4.49 ms\n",
      "Wall time: 30.1 ms\n"
     ]
    }
   ],
   "source": [
    "# SPark ML Pipeline\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"finished_chunk\", outputCol=\"features\", vocabSize=1000, minDF=10.0, minTF=10.0)\n",
    "idf = IDF(inputCol=\"features\", outputCol=\"idf\")\n",
    "lda = LDA(k=10, maxIter=5)\n",
    "### Let's create Spark-NLP Pipeline\n",
    "mlPipeline = Pipeline(stages=[\n",
    "    cv,\n",
    "    idf,\n",
    "    lda\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to train Spark ML Pipeline by using Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 149 ms, sys: 88.2 ms, total: 238 ms\n",
      "Wall time: 17min 59s\n"
     ]
    }
   ],
   "source": [
    "# Let's create Spark-NLP Pipeline\n",
    "mlModel = mlPipeline.fit(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 ms, sys: 9.08 ms, total: 32.7 ms\n",
      "Wall time: 95.5 ms\n"
     ]
    }
   ],
   "source": [
    "mlPipelineDF = mlModel.transform(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "|                text|      finished_chunk|    features|         idf|   topicDistribution|\n",
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "|The human KCNJ9 (...|[KCNJ9, Kir, GIRK...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|BACKGROUND: At pr...|[BACKGROUND, the ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To inv...|[OBJECTIVE, the r...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Combined EEG/fMRI...|[Combined EEG/fMR...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Kohlschutter synd...|[Kohlschutter, sy...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Statistical analy...|[Statistical, ana...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The synthetic DOX...|[DOX-LNA, conjuga...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Our objective was...|[objective, blood...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We conducted a ph...|[II, a phase, stu...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|\"Monomeric sarcos...|[Monomeric, MSOX,...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We presented the ...|[Exorista, Mythim...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The literature de...|[The literature, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|A novel approach ...|[A novel, approac...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|An HPLC-ESI-MS-MS...|[HPLC-ESI-MS-MS, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The localizing an...|[eye, head, durin...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To eva...|[OBJECTIVE, June,...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|For the construct...|[the construction...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We report the res...|[PNP, GSTO, Yaqui...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Intraparenchymal ...|[Intraparenchymal...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|It is known that ...|[Klinefelter, syn...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlPipelineDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldaModel = mlModel.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = ldaModel.logLikelihood(mlPipelineDF)\n",
    "lp = ldaModel.logPerplexity(mlPipelineDF)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+---------------+-------------------------------------------------------------------+\n",
      "|topic|termIndices    |termWeights                                                        |\n",
      "+-----+---------------+-------------------------------------------------------------------+\n",
      "|0    |[14, 548, 186] |[0.01585514997343471, 0.008875496465547342, 0.0013124023225362833] |\n",
      "|1    |[50, 954, 351] |[0.008349254284205958, 0.00753547628648889, 0.0013099340062148375] |\n",
      "|2    |[660, 475, 665]|[0.009414105927154907, 0.008065746072952672, 0.007336631079291149] |\n",
      "|3    |[0, 3, 830]    |[0.14763974789592677, 0.016467518100805777, 0.01128479619300655]   |\n",
      "|4    |[125, 927, 453]|[0.010021930458005748, 0.008013699542864731, 0.00783221889190857]  |\n",
      "|5    |[570, 72, 490] |[0.0087714655865149, 0.008257067329311462, 0.0012890162564849917]  |\n",
      "|6    |[362, 580, 101]|[0.007757053975635789, 0.007476033213583562, 0.007462557297979436] |\n",
      "|7    |[49, 26, 18]   |[0.02779804691969873, 0.02770300928643494, 0.014466074119477914]   |\n",
      "|8    |[206, 153, 527]|[0.006974791518068207, 0.001297899799192837, 0.001282128183382865] |\n",
      "|9    |[87, 543, 238] |[0.007517999445694715, 0.001313898633882325, 0.0013081840457029542]|\n",
      "+-----+---------------+-------------------------------------------------------------------+\n",
      "\n",
      "CPU times: user 2.18 ms, sys: 2.37 ms, total: 4.55 ms\n",
      "Wall time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "ldaModel.describeTopics(3).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at out topics\n",
    "NOTE: More cleaning, filtering, playing around with `CountVectorizer`, and more iterations in `LDA` will result in better Topic Modelling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 1000 words):\n",
      "topic:  0\n",
      "----------\n",
      "+\n",
      "IgE\n",
      "sensitivity\n",
      "muscle\n",
      "interval\n",
      "OBJECTIVE\n",
      "resection\n",
      "fraction\n",
      "inhibit\n",
      "distance\n",
      "thyroid\n",
      "diameter\n",
      "adult\n",
      "hypertension\n",
      "status\n",
      "tothe\n",
      "the role\n",
      "surface\n",
      "mmHg\n",
      "necrosis\n",
      "interest\n",
      "RF\n",
      "transcription\n",
      "balance\n",
      "CD4\n",
      "the onset\n",
      "stability\n",
      "a variety\n",
      "polymerase\n",
      "DNA\n",
      "disease\n",
      "mortality\n",
      "trial\n",
      "presence\n",
      "absence\n",
      "form\n",
      "absorption\n",
      "problem\n",
      "chromosome\n",
      "the degree\n",
      "the range\n",
      "Treatment\n",
      "tool\n",
      "brain\n",
      "prevalence\n",
      "inthe\n",
      "classification\n",
      "progression\n",
      "skin\n",
      "outcome\n",
      "----------\n",
      "topic:  1\n",
      "----------\n",
      "mice\n",
      "GnRH\n",
      "incidence\n",
      "receptor\n",
      "structure\n",
      "attention\n",
      "range\n",
      "CD4\n",
      "The method\n",
      "failure\n",
      "cleavage\n",
      "the range\n",
      "phase\n",
      "mitochondria\n",
      "susceptibility\n",
      "enhancement\n",
      "mucosal\n",
      "PSA\n",
      "deficiency\n",
      "vector\n",
      "skin\n",
      "damage\n",
      "The aim\n",
      "oxygen\n",
      "chemical\n",
      "percentage\n",
      "technology\n",
      "CF\n",
      "plant\n",
      "oxidase\n",
      "The expression\n",
      "delivery\n",
      "aureus\n",
      "mature\n",
      "the present study\n",
      "this work\n",
      "point\n",
      "evidence\n",
      "adjustment\n",
      "combination\n",
      "January\n",
      "preterm\n",
      "antigen\n",
      "blood\n",
      "IL-6\n",
      "the field\n",
      "tool\n",
      "SS\n",
      "dependence\n",
      "[\n",
      "----------\n",
      "topic:  2\n",
      "----------\n",
      "max\n",
      "ER\n",
      "AR\n",
      "Moreover\n",
      "product\n",
      "Mean\n",
      "search\n",
      "microscopy\n",
      "mutation\n",
      "mmHg\n",
      "extent\n",
      "education\n",
      "the response\n",
      "molecule\n",
      "enzyme\n",
      "birth\n",
      "impact\n",
      "the method\n",
      "lipid\n",
      "the activation\n",
      "regard\n",
      "transcription\n",
      "a total\n",
      "gel\n",
      "MAP\n",
      "use\n",
      "ischemia\n",
      "nerve\n",
      "microM\n",
      "the mean\n",
      "the group\n",
      "interference\n",
      "TNF-alpha\n",
      "understanding\n",
      "K\n",
      "half\n",
      "balance\n",
      "the treatment\n",
      "onthe\n",
      "length\n",
      "status\n",
      "the amount\n",
      "HIV\n",
      "J.\n",
      "control\n",
      "procedure\n",
      "part\n",
      "regression\n",
      "degree\n",
      "measurement\n",
      "----------\n",
      "topic:  3\n",
      "----------\n",
      "%\n",
      "P\n",
      "Type\n",
      "gel\n",
      "vivo\n",
      "function\n",
      "molecule\n",
      "disease\n",
      "artery\n",
      "chain\n",
      "the impact\n",
      "mucosal\n",
      "this paper\n",
      "a patient\n",
      "the prevalence\n",
      "allele\n",
      "),\n",
      "scale\n",
      "deficiency\n",
      "Serum\n",
      "host\n",
      "distribution\n",
      "diameter\n",
      "the first time\n",
      "myocardial\n",
      "nM\n",
      "accumulation\n",
      "trial\n",
      "month\n",
      "The purpose\n",
      "angle\n",
      "vaccination\n",
      "epithelium\n",
      "transmission\n",
      "sequence\n",
      "the induction\n",
      "AD\n",
      "the disease\n",
      "obesity\n",
      "deletion\n",
      "skin\n",
      "Moreover\n",
      "None\n",
      "yield\n",
      "the target\n",
      "recombinant\n",
      "HR\n",
      "the expression\n",
      "CD\n",
      "smoking\n",
      "----------\n",
      "topic:  4\n",
      "----------\n",
      "dose\n",
      "DCs\n",
      "iron\n",
      "uptake\n",
      "influence\n",
      "the possibility\n",
      "the management\n",
      "utilization\n",
      "root\n",
      "phosphatase\n",
      "neural\n",
      "inthe\n",
      "identification\n",
      "loci\n",
      "bythe\n",
      "optimal\n",
      "maintenance\n",
      "pH\n",
      "LPS\n",
      "muscle\n",
      "place\n",
      "specificity\n",
      "channel\n",
      "the addition\n",
      "contact\n",
      "temperature\n",
      "AA\n",
      "prostate\n",
      "the reaction\n",
      "amino acid\n",
      "locus\n",
      "operation\n",
      "ion\n",
      "culture\n",
      "chromosome\n",
      "June\n",
      "supplementation\n",
      "baseline\n",
      "kidney\n",
      "interest\n",
      "tomography\n",
      "fracture\n",
      "RR\n",
      "control\n",
      "sodium\n",
      "nasal\n",
      "angle\n",
      "the present study\n",
      "lack\n",
      "a case\n",
      "----------\n",
      "topic:  5\n",
      "----------\n",
      "diet\n",
      "mRNA\n",
      "gel\n",
      "intensity\n",
      "presence\n",
      "anterior\n",
      "staff\n",
      "inthe\n",
      "proximal\n",
      "mature\n",
      "a wide range\n",
      "optimal\n",
      "the end\n",
      "the influence\n",
      "operation\n",
      "task\n",
      "rest\n",
      "regard\n",
      "temperature\n",
      "suppression\n",
      "resolution\n",
      "evolution\n",
      "target\n",
      "site\n",
      "secretion\n",
      "test\n",
      "status\n",
      "recurrence\n",
      "percent\n",
      "no difference\n",
      "transcription\n",
      "viability\n",
      "range\n",
      "h.\n",
      "RF\n",
      "addition\n",
      "factor\n",
      "PET\n",
      "a number\n",
      "oxidation\n",
      "stimuli\n",
      "energy\n",
      "onset\n",
      "extent\n",
      "hospital\n",
      "(>\n",
      "diabetes\n",
      "patient\n",
      "resistance\n",
      "network\n",
      "----------\n",
      "topic:  6\n",
      "----------\n",
      "grade\n",
      "PA\n",
      "pain\n",
      "care\n",
      "medium\n",
      "part\n",
      "understanding\n",
      "approach\n",
      "interference\n",
      "fracture\n",
      "replacement\n",
      "satisfaction\n",
      "T\n",
      "epilepsy\n",
      "this method\n",
      "reconstruction\n",
      "laboratory\n",
      "the prevalence\n",
      "mg\n",
      "loci\n",
      "mass\n",
      "measurement\n",
      "neck\n",
      "microm\n",
      "relation\n",
      "access\n",
      "inthe\n",
      "secretion\n",
      "tube\n",
      "pretreatment\n",
      "mechanism\n",
      "example\n",
      "transmission\n",
      "method\n",
      "the group\n",
      "coli\n",
      "adhesion\n",
      "radiation\n",
      "place\n",
      "the proportion\n",
      "antagonist\n",
      "the amount\n",
      ">\n",
      "efficiency\n",
      "SNP\n",
      "a patient\n",
      "p53\n",
      "(>\n",
      "the evolution\n",
      "reference\n",
      "----------\n",
      "topic:  7\n",
      "----------\n",
      "]\n",
      "[\n",
      "p\n",
      "M\n",
      "<\n",
      "Zn\n",
      "blood\n",
      "center\n",
      "h.\n",
      "identification\n",
      "gain\n",
      "prevention\n",
      "agreement\n",
      "root\n",
      "the role\n",
      "BMI\n",
      "insulin\n",
      "addition\n",
      "intervention\n",
      "the possibility\n",
      "result\n",
      "uptake\n",
      "PD\n",
      "A.\n",
      "AIM\n",
      "vaccine\n",
      "the enzyme\n",
      "microscopy\n",
      "deficiency\n",
      "spectroscopy\n",
      "viability\n",
      "degradation\n",
      "(>\n",
      "measure\n",
      "anxiety\n",
      "IgG\n",
      "maintenance\n",
      "lesion\n",
      "This paper\n",
      "the first time\n",
      "a family\n",
      "antagonist\n",
      "education\n",
      "gel\n",
      "the risk\n",
      "diffuse\n",
      "recognition\n",
      "Overall\n",
      "accumulation\n",
      "T\n",
      "----------\n",
      "topic:  8\n",
      "----------\n",
      "repair\n",
      "number\n",
      "contact\n",
      "the need\n",
      "a family\n",
      "community\n",
      "environment\n",
      "the blood\n",
      "the addition\n",
      "June\n",
      "wall\n",
      "H.\n",
      "polymerase\n",
      "CF\n",
      "DNA\n",
      "mouse\n",
      "J.\n",
      "mM\n",
      "fever\n",
      "ATP\n",
      "adenosine\n",
      "initiation\n",
      "United\n",
      "home\n",
      "function\n",
      "research\n",
      "replacement\n",
      "HPLC\n",
      "<\n",
      "RNAs\n",
      "the ability\n",
      "methylation\n",
      "loss\n",
      "the treatment\n",
      "support\n",
      "sex\n",
      "plant\n",
      "lesion\n",
      "degradation\n",
      "the production\n",
      "disorder\n",
      "vaccine\n",
      "ELISA\n",
      "the present study\n",
      "ofthe\n",
      "half\n",
      "type\n",
      "mg\n",
      "point\n",
      "the left\n",
      "----------\n",
      "topic:  9\n",
      "----------\n",
      "glucose\n",
      "TB\n",
      "the patient\n",
      "role\n",
      "result\n",
      "microscopy\n",
      "wound\n",
      "benign\n",
      "cleavage\n",
      "side\n",
      "dementia\n",
      "CONCLUSION\n",
      "The use\n",
      "the quality\n",
      "associatedwith\n",
      "procedure\n",
      "adhesion\n",
      "kDa\n",
      "III\n",
      "education\n",
      "the severity\n",
      "a significant increase\n",
      "the lack\n",
      "The purpose\n",
      "shock\n",
      "ventricular\n",
      "IV\n",
      "i.e.\n",
      "technology\n",
      "radiation\n",
      "novel\n",
      "number\n",
      "+)\n",
      "production\n",
      ">\n",
      "value\n",
      "brain\n",
      "CSF\n",
      "initiation\n",
      "recurrence\n",
      "OBJECTIVES\n",
      "change\n",
      "condition\n",
      "accuracy\n",
      "water\n",
      "operation\n",
      "the disease\n",
      "testing\n",
      "H\n",
      "J.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "\n",
    "topics = ldaModel.describeTopics(50)\n",
    "topics_rdd = topics.rdd\n",
    "\n",
    "vocab = mlModel.stages[0].vocabulary\n",
    "\n",
    "topics_words = topics_rdd\\\n",
    "       .map(lambda row: row['termIndices'])\\\n",
    "       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "       .collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: \", idx)\n",
    "    print(\"----------\")\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
