{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nlp.johnsnowlabs.com/assets/images/logo.png\" width=\"180\" height=\"50\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global DEMO version 2.2.1\n",
    "\n",
    "## Example for Named Entity Recognition with Entity Resolution Pipeline\n",
    "A common NLP problem in biomedical aplications is to identify the presence of clinical entities in a given text. This clinical entities could be diseases, symptoms, drugs, results of clinical investigations or others.\n",
    "\n",
    "In this example we will use Spark-NLP to identify all the entities present in a typical clinical note.\n",
    "\n",
    "The clinical note (taken from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6553675/) is as follows:\n",
    "\n",
    "<div style=\"border:2px solid #747474; background-color: #e3e3e3; margin: 5px; padding: 10px\"> \n",
    "<p>A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and obesity with a body mass index (BMI) of 33.5 kg/m2, presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting. Two weeks prior to presentation, she was treated with a five-day course of amoxicillin for a respiratory tract infection. She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation.</p>\n",
    "\n",
    "<p>Physical examination on presentation was significant for dry oral mucosa; significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl, bicarbonate 18 mmol/l, anion gap 20, creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, glycated hemoglobin (HbA1c) 10%, and venous pH 7.27. Serum lipase was normal at 43 U/L. Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia.</p>\n",
    "\n",
    "<p>The patient was initially admitted for starvation ketosis, as she reported poor oral intake for three days prior to admission. However, serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL, the anion gap was still elevated at 21, serum bicarbonate was 16 mmol/L, triglyceride level peaked at 2050 mg/dL, and lipase was 52 U/L. The Î²-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again. The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL, within 24 hours. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use. The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely. She had close follow-up with endocrinology post discharge.</p>\n",
    "</div>\n",
    "\n",
    "We will use Spark-NLP capabilities to identify a list of medical problems, treatments and medical tests, and then try to assign a ICD-10 code to each element of this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Prepare the environment\n",
    "\n",
    "#### Install OpenSource spark-nlp and pyspark pip packages\n",
    "As a first step we import the required python dependences including some sparknlp components.\n",
    "\n",
    "Be sure that you have the required python libraries (pyspark 2.4.3, spark-nlp 2.2.1) by running <code>pip list</code>. Check that the versions are correct.\n",
    "\n",
    "If some of them is missing you can run:\n",
    "\n",
    "<code>pip install --ignore-installed pyspark==2.4.3</code><br>\n",
    "<code>pip install --ignore-installed spark-nlp==2.2.1</code><br>\n",
    "\n",
    "The --ignore-installed parameter is to overwrite your previous pip package version if already installed.\n",
    "\n",
    "<i>*If this cell fails means you have not propertly setup the required environment. Please check the pre-requisites guideline at http://www.johnsnowlabs.com</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.util import *\n",
    "from sparknlp.embeddings import *\n",
    "\n",
    "from sparknlp.embeddings import EmbeddingsHelper\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Licensed Sparl-NLP package\n",
    "\n",
    "We will use also some Spark-NLP enterprise functionalities contained in the spark-nlp-jsl package.\n",
    "\n",
    "You can check that spark-nlp-jsl is installed by running <code>pip install</code>. Check that version installed is 2.2.1.\n",
    "\n",
    "If it is not then you need to install it by using:\n",
    "\n",
    "<code>pip install spark-nlp-jsl==2.2.1 --extra-index-url #### --ignore-installed</code>\n",
    "\n",
    "The #### is a secret url, if you have not received it please contact us at info@johnsnowlabs.com.\n",
    "\n",
    "<i>*If the next cell fails means your licensed enterprise version is not propertly installed so please check the pre-requisites guideline at http://www.johnsnowlabs.com/</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this fails, means pip module for enterprise has not been properly set up\n",
    "\n",
    "from sparknlp_jsl.annotator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup credentials to private JohnSnowLabs models repository with AWS-CLI\n",
    "\n",
    "Now is time to configure Spark-NLP in order to access private JohnSnowLabs models repository. This access is done via Amazon aws command line interface (AWSCLI).\n",
    "\n",
    "Instructions about how to install awscli are available at: \n",
    "\n",
    "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html\n",
    "\n",
    "Make sure you configure your credentials with <code>aws configure</code> following the instructions at:\n",
    "\n",
    "https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html\n",
    "\n",
    "Please substitute the ACCESS_KEY and SECRET_KEY with the credentials you have recived. If you need your credentials contact us at info@johnsnowlabs.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Spark session\n",
    "\n",
    "The following will initialize the spark session in case you have run the jupyter notebook directly. If you have started the notebook using pyspark this cell is just ignored.\n",
    "\n",
    "Initializing the spark session takes some seconds (usually less than 1 minute) as the jar from the server needs to be loaded.\n",
    "\n",
    "We will be using version 2.2.1 of Spark NLP Open Source and 2.2.1 of Spark NLP Enterprise Edition.\n",
    "\n",
    "The #### in <code>.config(\"spark.jars\", \"####\")</code> is a secret code, if you have not received it please contact us at info@johnsnowlabs.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will be ignored if jupyter started using pyspark\n",
    "# This cell could take a while to run so be patient.\n",
    "# We will \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Global DEMO - Spark NLP Enterprise 2.2.1\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\",\"4G\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\") \\\n",
    "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.2.1\") \\\n",
    "    .config(\"spark.jars\", \"####\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Clinical NER Pipeline creation\n",
    "\n",
    "In Spark-NLP annotating NLP happens through pipelines. Pipelines are made out of various Annotator steps. In our case the architecture of the Clinical Named Entity Recognition pipeline will be:\n",
    "\n",
    "* DocumentAssembler (text -> document)\n",
    "* SentenceDetector (document -> sentence)\n",
    "* Tokenizer (sentence -> token)\n",
    "* WordEmbeddingsModel ([sentence, token] -> embeddings)\n",
    "* NerDLModel ([sentence, token, embeddings] -> ner)\n",
    "\n",
    "So from a text we end having a list of Named Entities (Patient problems, Treatments and Tests)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.1 Initialize all the annotators required by the pipeline\n",
    "\n",
    "The first 3 annotators of the pipeline are \"DocumentAssembler\", \"SentenceDectector\" and \"Tokenizer\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols([\"sentence\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth annotator in the pipeline is \"WordEmbeddingsModel\". We will download a pretrained model available from \"clinical/models\" named \"embeddings_clinical\".\n",
    "\n",
    "When running this cell your are advised to be patient. \n",
    "\n",
    "First time you call this pretrained model it needs to be downloaded in your local.\n",
    "\n",
    "The model size is about will download the embeddings_clinical corpus it takes a while.\n",
    "\n",
    "The size is about 1.7Gb and will be saved typically in your home folder as\n",
    "\n",
    "    ~HOMEFOLDER/cached_models/embeddings_clinical_en_2.0.2_2.4_1558454742956.zip\n",
    "\n",
    "Next times you call it the model is loaded from your cached copy but even in that case it needs to be indexed each time so expect waiting up to 5 minutes (depending on your machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# WordEmbeddingsModel pretrained \"embeddings_clinical\" includes a model of 1.7Gb that needs to be downloaded\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "  .setInputCols([\"sentence\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifth and final annotator in our NER pipeline is the pretrained \"ner_clinical\" NerDLModel avaliable from \"clinical/models\". It requires as input the \"sentence\", \"token\" and \"embeddings\" (clinical embeddings pretrained model) and will classify each token in four categories:\n",
    "<ol>\n",
    "    <li>PROBLEM: for patient problems</li>\n",
    "    <li>TEST: for tests, labs, etc.</li>\n",
    "    <li>TREATMENT: for treatments, medicines, etc.</li>\n",
    "    <li>OTHER: for the rest of tokens.</li>\n",
    "</ol>\n",
    "\n",
    "In order to split those identified NER that are consecutive, the B prefix (as B-PROBLEM) will be used at the first token of each NER. The I prefix (as I-PROBLEM) will be used for the rest of tokens inside the NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical download started this may take some time.\n",
      "Approximate size to download 13.8 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition for clinical concepts.\n",
    "\n",
    "clinical_ner = NerDLModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"ner\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2.2 Define the NER pipeline\n",
    "\n",
    "Now we will define the actual pipeline that puts together the annotators we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up the pipeline\n",
    "\n",
    "pipeline_ner = Pipeline(\n",
    "    stages = [\n",
    "    documentAssembler,\n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Create a SparkDataFrame with the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a sample Spark dataframe with our clinical note example.\n",
    "\n",
    "In this example we are working over a unique clinical note. In production environments a table with several of those clinical notes could be distributed in a cluster and be run in large scale systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6553675/\n",
    "\n",
    "clinical_note = (\n",
    "    'A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years '\n",
    "    'prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior '\n",
    "    'episode of HTG-induced pancreatitis three years prior to presentation, associated '\n",
    "    'with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, '\n",
    "    'presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting. '\n",
    "    'Two weeks prior to presentation, she was treated with a five-day course of amoxicillin '\n",
    "    'for a respiratory tract infection. She was on metformin, glipizide, and dapagliflozin '\n",
    "    'for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months '\n",
    "    'at the time of presentation. Physical examination on presentation was significant for dry oral mucosa; '\n",
    "    'significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent '\n",
    "    'laboratory findings on admission were: serum glucose 111 mg/dl, bicarbonate 18 mmol/l, anion gap 20, '\n",
    "    'creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, glycated hemoglobin (HbA1c) '\n",
    "    '10%, and venous pH 7.27. Serum lipase was normal at 43 U/L. Serum acetone levels could not be assessed '\n",
    "    'as blood samples kept hemolyzing due to significant lipemia. The patient was initially admitted for '\n",
    "    'starvation ketosis, as she reported poor oral intake for three days prior to admission. However, '\n",
    "    'serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL, the anion gap '\n",
    "    'was still elevated at 21, serum bicarbonate was 16 mmol/L, triglyceride level peaked at 2050 mg/dL, and '\n",
    "    'lipase was 52 U/L. The Î²-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - '\n",
    "    'the original sample was centrifuged and the chylomicron layer removed prior to analysis due to '\n",
    "    'interference from turbidity caused by lipemia again. The patient was treated with an insulin drip '\n",
    "    'for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL, within '\n",
    "    '24 hours. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting '\n",
    "    'of SGLT2 inhibitor use. The patient was seen by the endocrinology service and she was discharged on '\n",
    "    '40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg '\n",
    "    'two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely. She '\n",
    "    'had close follow-up with endocrinology post discharge.'\n",
    ")\n",
    "\n",
    "data_ner = spark.createDataFrame([[clinical_note]]).toDF(\"text\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|A 28-year-old fem...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_ner.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Create a model fiting the NER pipeline with the clinical note.\n",
    "\n",
    "Now we can use the pipeline and the clinical note to generate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert the pipeline into a model fitting our clinical note (data).\n",
    "model_ner = pipeline_ner.fit(data_ner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Transform/annotate the clinical note using the model.\n",
    "\n",
    "In order to process the data with the new created model we have two options.\n",
    "\n",
    "The first one would be to use the model to transform our clinical note by the command:\n",
    "\n",
    "<code>output = model_ner.transform(data_ner)</code>\n",
    "\n",
    "That would save in a Spakr DataFrame (output) the resuls of running the model over the clinical note. \n",
    "\n",
    "However for small tests like this or for real-time request a LightPipelines is a simpler way of managing the data. It will return a dictionary (instead of a Spark DataFrame) with the results of the transformation\n",
    "\n",
    "We will create a light_pipeline_ner using our model_ner and then will annotate the clinical_note using this light_pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_pipeline = LightPipeline(model_ner)\n",
    "light_data = light_pipeline.annotate(clinical_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dictionaty (light_data_ner) that contains the results of running the NER pipeline over our clinical note.\n",
    "\n",
    "It contains the original document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_data['document'][0][0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 17 sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 17\n",
      "\n",
      "Sentence 0: A 28-year-old female with a history of gestational diabetes mellitus diagnosed e\n",
      "Sentence 1: Two weeks prior to presentation, she was treated with a five-day course of amoxi\n",
      "Sentence 2: She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and\n",
      "Sentence 3: She had been on dapagliflozin for six months at the time of presentation.\n",
      "Sentence 4: Physical examination on presentation was significant for dry oral mucosa;\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences: {}\".format(len(light_data['sentence'])))\n",
    "print(\"\")\n",
    "for i in range(5):\n",
    "    print(\"Sentence {}: {}\".format(i, light_data['sentence'][i][0:80]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the 437 tokens with their assigned NER class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 436\n",
      "\n",
      "Token 0: A (O)\n",
      "Token 1: 28-year-old (O)\n",
      "Token 2: female (O)\n",
      "Token 3: with (O)\n",
      "Token 4: a (O)\n",
      "Token 5: history (O)\n",
      "Token 6: of (O)\n",
      "Token 7: gestational (B-PROBLEM)\n",
      "Token 8: diabetes (I-PROBLEM)\n",
      "Token 9: mellitus (I-PROBLEM)\n",
      "Token 10: diagnosed (O)\n",
      "Token 11: eight (O)\n",
      "Token 12: years (O)\n",
      "Token 13: prior (O)\n",
      "Token 14: to (O)\n",
      "Token 15: presentation (O)\n",
      "Token 16: and (O)\n",
      "Token 17: subsequent (O)\n",
      "Token 18: type (B-PROBLEM)\n",
      "Token 19: two (I-PROBLEM)\n",
      "Token 20: diabetes (I-PROBLEM)\n",
      "Token 21: mellitus (I-PROBLEM)\n",
      "Token 22: ( (O)\n",
      "Token 23: T2DM (B-PROBLEM)\n",
      "Token 24: ), (I-PROBLEM)\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens: {}\".format(len(light_data['token'])))\n",
    "print(\"\")\n",
    "for i in range(25):\n",
    "    print(\"Token {}: {} ({})\".format(i, light_data['token'][i][0:20], light_data['ner'][i]))\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets apply some HTML formating to see the results of the pipeline in a nicer layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><h2>Results of NER Annotation Pipeline</h2></center><div style=\"border:2px solid #747474; background-color: #e3e3e3; margin: 5px; padding: 10px\">A 28-year-old female with a history of <SPAN style=\"background-color: #ffffcc\">gestational </SPAN><SPAN style=\"background-color: #ffffcc\">diabetes </SPAN><SPAN style=\"background-color: #ffffcc\">mellitus </SPAN>diagnosed eight years prior to presentation and subsequent <SPAN style=\"background-color: #ffffcc\">type </SPAN><SPAN style=\"background-color: #ffffcc\">two </SPAN><SPAN style=\"background-color: #ffffcc\">diabetes </SPAN><SPAN style=\"background-color: #ffffcc\">mellitus </SPAN>( <SPAN style=\"background-color: #ffffcc\">T2DM </SPAN><SPAN style=\"background-color: #ffffcc\">), </SPAN>one prior episode of <SPAN style=\"background-color: #ffffcc\">HTG-induced </SPAN><SPAN style=\"background-color: #ffffcc\">pancreatitis </SPAN>three years prior to presentation , associated with <SPAN style=\"background-color: #ffffcc\">an </SPAN><SPAN style=\"background-color: #ffffcc\">acute </SPAN><SPAN style=\"background-color: #ffffcc\">hepatitis </SPAN>, and <SPAN style=\"background-color: #ffffcc\">obesity </SPAN>with <SPAN style=\"background-color: #ffffcc\">a </SPAN><SPAN style=\"background-color: #ffffcc\">body </SPAN><SPAN style=\"background-color: #ffffcc\">mass </SPAN><SPAN style=\"background-color: #ffffcc\">index </SPAN>( BMI ) of 33.5 kg/m2 , presented with a one-week history of <SPAN style=\"background-color: #ffffcc\">polyuria </SPAN>, <SPAN style=\"background-color: #ffffcc\">polydipsia </SPAN>, <SPAN style=\"background-color: #ffffcc\">poor </SPAN><SPAN style=\"background-color: #ffffcc\">appetite </SPAN>, and <SPAN style=\"background-color: #ffffcc\">vomiting </SPAN>. Two weeks prior to presentation , she was treated with a five-day course of <SPAN style=\"background-color:  #cce6ff\">amoxicillin </SPAN>for <SPAN style=\"background-color: #ffffcc\">a </SPAN><SPAN style=\"background-color: #ffffcc\">respiratory </SPAN><SPAN style=\"background-color: #ffffcc\">tract </SPAN><SPAN style=\"background-color: #ffffcc\">infection </SPAN>. She was on <SPAN style=\"background-color:  #cce6ff\">metformin </SPAN>, <SPAN style=\"background-color:  #cce6ff\">glipizide </SPAN>, and <SPAN style=\"background-color:  #cce6ff\">dapagliflozin </SPAN>for <SPAN style=\"background-color: #ffffcc\">T2DM </SPAN>and <SPAN style=\"background-color:  #cce6ff\">atorvastatin </SPAN>and <SPAN style=\"background-color:  #cce6ff\">gemfibrozil </SPAN>for <SPAN style=\"background-color: #ffffcc\">HTG </SPAN>. She had been on <SPAN style=\"background-color:  #cce6ff\">dapagliflozin </SPAN>for six months at the time of presentation . <SPAN style=\"background-color: pink\">Physical </SPAN><SPAN style=\"background-color: pink\">examination </SPAN>on presentation was significant for dry oral mucosa ; significantly , <SPAN style=\"background-color: pink\">her </SPAN><SPAN style=\"background-color: pink\">abdominal </SPAN><SPAN style=\"background-color: pink\">examination </SPAN>was benign with no <SPAN style=\"background-color: #ffffcc\">tenderness </SPAN>, <SPAN style=\"background-color: #ffffcc\">guarding </SPAN>, or <SPAN style=\"background-color: #ffffcc\">rigidity </SPAN>. Pertinent laboratory findings on admission were : <SPAN style=\"background-color: pink\">serum </SPAN><SPAN style=\"background-color: pink\">glucose </SPAN>111 <SPAN style=\"background-color: pink\">mg/dl </SPAN>, <SPAN style=\"background-color: pink\">bicarbonate </SPAN>18 mmol/l , <SPAN style=\"background-color: pink\">anion </SPAN><SPAN style=\"background-color: pink\">gap </SPAN>20 , <SPAN style=\"background-color: pink\">creatinine </SPAN>0.4 <SPAN style=\"background-color: pink\">mg/dL </SPAN>, <SPAN style=\"background-color: pink\">triglycerides </SPAN>508 <SPAN style=\"background-color: pink\">mg/dL </SPAN>, <SPAN style=\"background-color: pink\">total </SPAN><SPAN style=\"background-color: pink\">cholesterol </SPAN>122 <SPAN style=\"background-color: pink\">mg/dL </SPAN>, <SPAN style=\"background-color: pink\">glycated </SPAN><SPAN style=\"background-color: pink\">hemoglobin </SPAN>( <SPAN style=\"background-color: pink\">HbA1c </SPAN>) 10% , and <SPAN style=\"background-color: pink\">venous </SPAN><SPAN style=\"background-color: pink\">pH </SPAN>7.27 . <SPAN style=\"background-color: pink\">Serum </SPAN><SPAN style=\"background-color: pink\">lipase </SPAN>was normal at 43 <SPAN style=\"background-color: pink\">U/L </SPAN>. <SPAN style=\"background-color: pink\">Serum </SPAN><SPAN style=\"background-color: pink\">acetone </SPAN><SPAN style=\"background-color: pink\">levels </SPAN>could not be assessed as <SPAN style=\"background-color: pink\">blood </SPAN><SPAN style=\"background-color: pink\">samples </SPAN>kept <SPAN style=\"background-color: pink\">hemolyzing </SPAN>due to <SPAN style=\"background-color: #ffffcc\">significant </SPAN><SPAN style=\"background-color: #ffffcc\">lipemia </SPAN>. The patient was initially admitted for <SPAN style=\"background-color: #ffffcc\">starvation </SPAN><SPAN style=\"background-color: #ffffcc\">ketosis </SPAN>, as she reported <SPAN style=\"background-color: #ffffcc\">poor </SPAN><SPAN style=\"background-color: #ffffcc\">oral </SPAN><SPAN style=\"background-color: #ffffcc\">intake </SPAN>for three days prior to admission . However , <SPAN style=\"background-color: pink\">serum </SPAN><SPAN style=\"background-color: pink\">chemistry </SPAN>obtained six hours after presentation revealed <SPAN style=\"background-color: pink\">her </SPAN><SPAN style=\"background-color: pink\">glucose </SPAN>was 186 <SPAN style=\"background-color: pink\">mg/dL </SPAN>, <SPAN style=\"background-color: pink\">the </SPAN><SPAN style=\"background-color: pink\">anion </SPAN><SPAN style=\"background-color: pink\">gap </SPAN>was <SPAN style=\"background-color: #ffffcc\">still </SPAN><SPAN style=\"background-color: #ffffcc\">elevated </SPAN>at 21 , <SPAN style=\"background-color: pink\">serum </SPAN><SPAN style=\"background-color: pink\">bicarbonate </SPAN>was 16 mmol/L , <SPAN style=\"background-color: pink\">triglyceride </SPAN><SPAN style=\"background-color: pink\">level </SPAN>peaked at 2050 <SPAN style=\"background-color: pink\">mg/dL </SPAN>, and <SPAN style=\"background-color: pink\">lipase </SPAN>was 52 <SPAN style=\"background-color: pink\">U/L </SPAN>. <SPAN style=\"background-color: pink\">The </SPAN><SPAN style=\"background-color: pink\">Î²-hydroxybutyrate </SPAN><SPAN style=\"background-color: pink\">level </SPAN>was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and <SPAN style=\"background-color: pink\">the </SPAN><SPAN style=\"background-color: pink\">chylomicron </SPAN><SPAN style=\"background-color: pink\">layer </SPAN>removed prior to <SPAN style=\"background-color: pink\">analysis </SPAN>due to <SPAN style=\"background-color: #ffffcc\">interference </SPAN><SPAN style=\"background-color: #ffffcc\">from </SPAN><SPAN style=\"background-color: #ffffcc\">turbidity </SPAN>caused by <SPAN style=\"background-color: #ffffcc\">lipemia </SPAN>again . The patient was treated with <SPAN style=\"background-color:  #cce6ff\">an </SPAN><SPAN style=\"background-color:  #cce6ff\">insulin </SPAN><SPAN style=\"background-color:  #cce6ff\">drip </SPAN>for <SPAN style=\"background-color: #ffffcc\">euDKA </SPAN>and <SPAN style=\"background-color: #ffffcc\">HTG </SPAN>with <SPAN style=\"background-color: #ffffcc\">a </SPAN><SPAN style=\"background-color: #ffffcc\">reduction </SPAN><SPAN style=\"background-color: #ffffcc\">in </SPAN><SPAN style=\"background-color: #ffffcc\">the </SPAN><SPAN style=\"background-color: #ffffcc\">anion </SPAN><SPAN style=\"background-color: #ffffcc\">gap </SPAN>to 13 and <SPAN style=\"background-color: pink\">triglycerides </SPAN>to 1400 <SPAN style=\"background-color: pink\">mg/dL </SPAN>, within 24 hours . <SPAN style=\"background-color: #ffffcc\">Her </SPAN><SPAN style=\"background-color: #ffffcc\">euDKA </SPAN>was thought to be precipitated by <SPAN style=\"background-color: #ffffcc\">her </SPAN><SPAN style=\"background-color: #ffffcc\">respiratory </SPAN><SPAN style=\"background-color: #ffffcc\">tract </SPAN><SPAN style=\"background-color: #ffffcc\">infection </SPAN>in the setting of <SPAN style=\"background-color:  #cce6ff\">SGLT2 </SPAN><SPAN style=\"background-color:  #cce6ff\">inhibitor </SPAN>use . The patient was seen by the endocrinology service and she was discharged on 40 units of <SPAN style=\"background-color:  #cce6ff\">insulin </SPAN><SPAN style=\"background-color:  #cce6ff\">glargine </SPAN>at night , 12 units of <SPAN style=\"background-color:  #cce6ff\">insulin </SPAN><SPAN style=\"background-color:  #cce6ff\">lispro </SPAN>with meals , and <SPAN style=\"background-color:  #cce6ff\">metformin </SPAN>1000 mg two times a day . It was determined that <SPAN style=\"background-color:  #cce6ff\">all </SPAN><SPAN style=\"background-color:  #cce6ff\">SGLT2 </SPAN><SPAN style=\"background-color:  #cce6ff\">inhibitors </SPAN>should be discontinued indefinitely . She had close follow-up with endocrinology post discharge . </div><div>Color codes: <SPAN style=\"background-color: #ffffcc\">Patient problem</SPAN>, <SPAN style=\"background-color: pink\">Test</SPAN>, <SPAN style=\"background-color: #cce6ff\">Treatment</SPAN>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "html_output = '<center><h2>Results of NER Annotation Pipeline</h2></center>'\n",
    "html_output += '<div style=\"border:2px solid #747474; background-color: #e3e3e3; margin: 5px; padding: 10px\">'\n",
    "problem_flag = False\n",
    "new_problem = []\n",
    "problem_list = []\n",
    "for index, this_token in enumerate(light_data['token']):\n",
    "    \n",
    "    if light_data['ner'][index] in ['B-PROBLEM','I-PROBLEM']:\n",
    "        if problem_flag == False:\n",
    "            new_problem = [this_token]\n",
    "        else:\n",
    "            new_problem.append(this_token)\n",
    "        problem_flag = True\n",
    "    else:\n",
    "        if problem_flag == True:\n",
    "            problem_list.append(new_problem)\n",
    "            new_problem = []\n",
    "        problem_flag = False\n",
    "    \n",
    "    if light_data['ner'][index]=='O':\n",
    "        html_output+=this_token + \" \"\n",
    "    elif light_data['ner'][index]=='B-PROBLEM':\n",
    "        html_output+='<SPAN style=\"background-color: #ffffcc\">' + this_token + \" </SPAN>\"\n",
    "    elif light_data['ner'][index]=='I-PROBLEM':\n",
    "        html_output+='<SPAN style=\"background-color: #ffffcc\">' + this_token + \" </SPAN>\"\n",
    "    elif light_data['ner'][index]=='B-TEST':\n",
    "        html_output+='<SPAN style=\"background-color: pink\">' + this_token + \" </SPAN>\"\n",
    "    elif light_data['ner'][index]=='I-TEST':\n",
    "        html_output+='<SPAN style=\"background-color: pink\">' + this_token + \" </SPAN>\"\n",
    "    elif light_data['ner'][index]=='B-TREATMENT':\n",
    "        html_output+='<SPAN style=\"background-color:  #cce6ff\">' + this_token + \" </SPAN>\"\n",
    "    elif light_data['ner'][index]=='I-TREATMENT':\n",
    "        html_output+='<SPAN style=\"background-color:  #cce6ff\">' + this_token + \" </SPAN>\"\n",
    "    \n",
    "\n",
    "html_output += '</div>'\n",
    "        \n",
    "html_output += '<div>Color codes: <SPAN style=\"background-color: #ffffcc\">Patient problem</SPAN>, '\n",
    "html_output += '<SPAN style=\"background-color: pink\">Test</SPAN>, '\n",
    "html_output += '<SPAN style=\"background-color: #cce6ff\">Treatment</SPAN>'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(html_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 ICD10 coding Pipeline creation.\n",
    "\n",
    "After running the NER Pipeline we have been able to extract a list of \"Patient Problems\" that is printed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gestational diabetes mellitus\n",
      "type two diabetes mellitus\n",
      "T2DM ),\n",
      "HTG-induced pancreatitis\n",
      "an acute hepatitis\n",
      "obesity\n",
      "a body mass index\n",
      "polyuria\n",
      "polydipsia\n",
      "poor appetite\n",
      "vomiting\n",
      "a respiratory tract infection\n",
      "T2DM\n",
      "HTG\n",
      "tenderness\n",
      "guarding\n",
      "rigidity\n",
      "significant lipemia\n",
      "starvation ketosis\n",
      "poor oral intake\n",
      "still elevated\n",
      "interference from turbidity\n",
      "lipemia\n",
      "euDKA\n",
      "HTG\n",
      "a reduction in the anion gap\n",
      "Her euDKA\n",
      "her respiratory tract infection\n"
     ]
    }
   ],
   "source": [
    "for problem in problem_list:\n",
    "    print(\" \".join(problem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a new pipeline that from each of these problems will try to assign an ICD10 base on the content, the wordembeddings and some pretrained models for ICD10 annotation.\n",
    "\n",
    "The architecture of this new pipeline will be as follows:\n",
    "* DocumentAssembler (text -> document)\n",
    "* SentenceDetector (document -> sentence)\n",
    "* Tokenizer (sentence -> token)\n",
    "* WordEmbeddingsModel ([sentence, token] -> embeddings)\n",
    "* NerDLModel ([sentence, token, embeddings] -> ner)\n",
    "* NerConverter ([\"sentence, token, ner] -> ner_chunk\n",
    "* ChunkTokenizer (ner_chunk -> ner_chunk_tokenized)\n",
    "* ICD10CMEntityResolverModel ([ner_chunk_tokenized, embeddings] -> resolution)\n",
    "* ICD10PCSEntityResolverModel ([ner_chunk_tokenized, embeddings] -> resolution)\n",
    "\n",
    "So from a text we end having a list of Named Entities (ner_chunk) and their ICD10 codes (resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the annotators in this pipeline have been already created for the previous pipeline, but we need to create four additional annotators: NerConverter, ChunkTokenizer, EntityResolverModel for ICD10CM and EntityResolverModel for ICD10PCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Entity Recognition concepts parser, transforms entities into CHUNKS (required for next step: assertion status)\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# We have to tokenize the chunks, to fullfil EntityResolver requirements of TOKEN\n",
    "\n",
    "chunk_tokenizer = ChunkTokenizer() \\\n",
    "  .setInputCols([\"ner_chunk\"]) \\\n",
    "  .setOutputCol(\"ner_chunk_tokenized\")\n",
    "\n",
    "# ICD resolution model\n",
    "\n",
    "icd_resolution_cm = EntityResolverModel.pretrained(\"resolve_icd10cm_cl_em\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"ner_chunk_tokenized\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"resolution_cm\") \\\n",
    "  .setThreshold(10)\n",
    "\n",
    "#PCS Resolution\n",
    "icd_resolution_pcs = EntityResolverModel.pretrained(\"resolve_icd10pcs_cl_em\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"ner_chunk_tokenized\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"resolution_pcs\") \\\n",
    "  .setThreshold(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up the pipeline\n",
    "\n",
    "pipeline_icd10 = Pipeline(\n",
    "    stages = [\n",
    "    documentAssembler,\n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    chunk_tokenizer,\n",
    "    icd_resolution_cm,\n",
    "    icd_resolution_pcs\n",
    "  ])\n",
    "\n",
    "model_icd10 = pipeline_icd10.fit(data_ner)\n",
    "light_pipeline_icd10 = LightPipeline(model_icd10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the patient problems identified in the clinical note, we can run the ICD10 resolution pipeline and in case we found a candidate ICD10 code we print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "ICD10 codes identified for the list of patients problems found in the clinical note.\n",
      "====================================================================================\n",
      "gestational diabetes mellitus >>> ICD10CM: P702\n",
      "type two diabetes mellitus >>> ICD10CM: E1165\n",
      "T2DM ), >>> ICD10CM: R7303\n",
      "HTG-induced pancreatitis >>> ICD10CM: B252\n",
      "an acute hepatitis >>> ICD10CM: B172\n",
      "obesity >>> ICD10CM: E663\n",
      "polyuria >>> ICD10CM: R632\n",
      "polydipsia >>> ICD10CM: R631\n",
      "vomiting >>> ICD10CM: R110\n",
      "T2DM >>> ICD10CM: R7303\n",
      "still elevated >>> ICD10CM: E7841\n"
     ]
    }
   ],
   "source": [
    "# Now for the list of Patient Problem entities we will run the LightPipeline\n",
    "problem_list_str = [\" \".join(this_problem) for this_problem in problem_list]\n",
    "\n",
    "print(\"====================================================================================\")\n",
    "print(\"ICD10 codes identified for the list of patients problems found in the clinical note.\")\n",
    "print(\"====================================================================================\")\n",
    "\n",
    "for problem in problem_list_str:\n",
    "    this_r = light_pipeline_icd10.annotate(problem)\n",
    "    if(len(this_r['resolution_cm'])>0):\n",
    "        print(\"{} >>> ICD10CM: {}\".format(this_r['sentence'][0], this_r['resolution_cm'][0]))\n",
    "    if(len(this_r['resolution_pcs'])>0):\n",
    "        print(\"{} >>> ICD10CM: {}\".format(this_r['sentence'][0], this_r['resolution_pcs'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
