{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install `spark-nlp` in Python\n",
    "\n",
    "* pip\n",
    "\n",
    "```\n",
    "pip install spark-nlp==2.3.4\n",
    "```\n",
    "\n",
    "* Conda\n",
    "\n",
    "```\n",
    "conda install -c johnsnowlabs spark-nlp==2.3.4\n",
    "```\n",
    "\n",
    "### NGramGenerator\n",
    "\n",
    "`NGramGenerator` annotator takes as input a sequence of strings (e.g. the output of a `Tokenizer`, `Normalizer`, `Stemmer`, `Lemmatizer`, and `StopWordsCleaner`). The parameter `n` is used to determine the number of terms in each n-gram. The output will consist of a sequence of n-grams where each n-gram is represented by a space-delimited string of n consecutive words with annotatorType `CHUNK` same as the `Chunker` annotator.\n",
    "\n",
    "**Output type:** CHUNK  \n",
    "**Input types:** TOKEN  \n",
    "**Reference:** [NGramGenerator](https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/NGramGenerator.scala)  \n",
    "**Functions:**\n",
    "\n",
    "- setN: number elements per n-gram (>=1)\n",
    "- setEnableCumulative: whether to calculate just the actual n-grams or all n-grams from 1 through n\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Refer to the [NGramGenerator](https://nlp.johnsnowlabs.com/api/index#com.johnsnowlabs.nlp.annotators.NGramGenerator) Scala docs for more details on the API.\n",
    "\n",
    "```python\n",
    "ngrams_cum = NGramGenerator() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"ngrams\") \\\n",
    "            .setN(2) \\\n",
    "            .setEnableCumulative(True)\n",
    "```\n",
    "\n",
    "```scala\n",
    "val nGrams = new NGramGenerator()\n",
    "      .setInputCols(\"token\")\n",
    "      .setOutputCol(\"ngrams\")\n",
    "      .setN(2)\n",
    "      .setEnableCumulative(true)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.4'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = spark.createDataFrame([\n",
    "    \"Cloud computing is benefiting major manufacturing companies\",\n",
    "    \"Big data cloud computing cyber security machine learning\"\n",
    "], StringType()).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "bigrams = NGramGenerator() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"bigrams\") \\\n",
    "            .setN(2)\n",
    "\n",
    "trigrams_cum = NGramGenerator() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"trigrams\") \\\n",
    "            .setN(3)            \n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer, \n",
    "    bigrams,\n",
    "    trigrams_cum\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Pipeline in Spark (DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(dfTest)\n",
    "prediction = model.transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|                                                      result|\n",
      "+------------------------------------------------------------+\n",
      "|[Cloud computing, computing is, is benefiting, benefiting...|\n",
      "|[Big data, data cloud, cloud computing, computing cyber, ...|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"bigrams.result\").show(2, truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|                                                      result|\n",
      "+------------------------------------------------------------+\n",
      "|[Cloud computing is, computing is benefiting, is benefiti...|\n",
      "|[Big data cloud, data cloud computing, cloud computing cy...|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"trigrams.result\").show(2, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Pipeline in Python (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import LightPipeline\n",
    "\n",
    "text = 'Cloud computing is benefiting major manufacturing companies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = LightPipeline(model).annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['document', 'token', 'bigrams', 'trigrams']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cloud computing',\n",
       " 'computing is',\n",
       " 'is benefiting',\n",
       " 'benefiting major',\n",
       " 'major manufacturing',\n",
       " 'manufacturing companies']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['bigrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cloud computing is',\n",
       " 'computing is benefiting',\n",
       " 'is benefiting major',\n",
       " 'benefiting major manufacturing',\n",
       " 'major manufacturing companies']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['trigrams']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
