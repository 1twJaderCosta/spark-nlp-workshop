{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = DocumentAssembler().setInputCol('text').setOutputCol('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCols('document').setOutputCol('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pos = PerceptronModel.pretrained().setInputCols('document', 'token').setOutputCol('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([document, tokenizer, pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.text('./sample-sentences-en.txt').toDF('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Peter is a very g...|\n",
      "|My life in Russia...|\n",
      "|John and Peter ar...|\n",
      "|Lucas Nogal Dunbe...|\n",
      "|Europe is very cu...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|               token|                 pos|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Peter is a very g...|[[document, 0, 27...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|\n",
      "|My life in Russia...|[[document, 0, 37...|[[token, 0, 1, My...|[[pos, 0, 1, PRP$...|\n",
      "|John and Peter ar...|[[document, 0, 76...|[[token, 0, 3, Jo...|[[pos, 0, 3, NNP,...|\n",
      "|Lucas Nogal Dunbe...|[[document, 0, 67...|[[token, 0, 4, Lu...|[[pos, 0, 4, NNP,...|\n",
      "|Europe is very cu...|[[document, 0, 68...|[[token, 0, 5, Eu...|[[pos, 0, 5, NNP,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = result\\\n",
    "  .select('text', 'pos.begin', 'pos.end', 'pos.result', 'pos.metadata')\\\n",
    "  .toDF('text', 'pos_begin', 'pos_end', 'pos_result', 'pos_meta')\\\n",
    "  .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- pos_begin: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- pos_end: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- pos_result: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- pos_meta: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|           pos_begin|             pos_end|          pos_result|            pos_meta|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Peter is a very g...|[0, 6, 9, 11, 16,...|[4, 7, 9, 14, 19,...|[NNP, VBZ, DT, RB...|[[word -> Peter],...|\n",
      "|My life in Russia...|[0, 3, 8, 11, 18,...|[1, 6, 9, 16, 19,...|[PRP$, NN, IN, NN...|[[word -> My], [w...|\n",
      "|John and Peter ar...|[0, 5, 9, 15, 19,...|[3, 7, 13, 17, 26...|[NNP, CC, NNP, VB...|[[word -> John], ...|\n",
      "|Lucas Nogal Dunbe...|[0, 6, 12, 23, 26...|[4, 10, 21, 24, 2...|[NNP, NNP, NNP, V...|[[word -> Lucas],...|\n",
      "|Europe is very cu...|[0, 7, 10, 15, 23...|[5, 8, 13, 21, 26...|[NNP, VBZ, RB, RB...|[[word -> Europe]...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## Spark SQL Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-------+----------+--------+\n",
      "|text|pos_begin|pos_end|pos_result|pos_meta|\n",
      "+----+---------+-------+----------+--------+\n",
      "+----+---------+-------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.filter(array_contains('pos_result', 'VBD')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          pos_result|token_count|\n",
      "+--------------------+-----------+\n",
      "|[NNP, VBZ, DT, RB...|          7|\n",
      "|[PRP$, NN, IN, NN...|          8|\n",
      "|[NNP, CC, NNP, VB...|         15|\n",
      "|[NNP, NNP, NNP, V...|         15|\n",
      "|[NNP, VBZ, RB, RB...|         15|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.withColumn('token_count', size('pos_result')).select('pos_result', 'token_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                text|array_max(pos_end)|\n",
      "+--------------------+------------------+\n",
      "|Peter is a very g...|                27|\n",
      "|My life in Russia...|                37|\n",
      "|John and Peter ar...|                76|\n",
      "|Lucas Nogal Dunbe...|                67|\n",
      "|Europe is very cu...|                68|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.select('text', array_max('pos_end')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          pos_result|          unique_pos|\n",
      "+--------------------+--------------------+\n",
      "|[NNP, VBZ, DT, RB...|[NNP, VBZ, DT, RB...|\n",
      "|[PRP$, NN, IN, NN...|[PRP$, NN, IN, NN...|\n",
      "|[NNP, CC, NNP, VB...|[NNP, CC, VBP, NN...|\n",
      "|[NNP, NNP, NNP, V...|[NNP, VBZ, DT, RB...|\n",
      "|[NNP, VBZ, RB, RB...|[NNP, VBZ, RB, JJ...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.withColumn('unique_pos', array_distinct('pos_result')).select('pos_result', 'unique_pos').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-----+\n",
      "|array_sort(array_distinct(pos_result))|count|\n",
      "+--------------------------------------+-----+\n",
      "|                  [., CC, EX, JJ, N...|    1|\n",
      "|                  [., IN, JJ, NN, N...|    1|\n",
      "|                  [., CC, DT, IN, J...|    1|\n",
      "|                  [., DT, IN, JJ, N...|    1|\n",
      "|                  [., DT, JJ, NN, N...|    1|\n",
      "+--------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.groupBy(array_sort(array_distinct('pos_result'))).count().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "### SQL Functions with `col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|pos_meta[0][word]|\n",
      "+-----------------+\n",
      "|            Peter|\n",
      "|               My|\n",
      "|             John|\n",
      "|            Lucas|\n",
      "|           Europe|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.select(col('pos_meta').getItem(0).getItem('word')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Spark NLP Annotation UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|pos                                                                                                                                                                                                                                                                    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[pos, 0, 4, NNP, [word -> Peter], []], [pos, 6, 7, VBZ, [word -> is], []], [pos, 9, 9, DT, [word -> a], []], [pos, 11, 14, RB, [word -> very], []], [pos, 16, 19, JJ, [word -> good], []], [pos, 21, 26, NN, [word -> person], []], [pos, 27, 27, ., [word -> .], []]]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('pos').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_tokens(annotations):\n",
    "    nn_annotations = list(\n",
    "        filter(lambda annotation: annotation.result == 'NN', annotations)\n",
    "    )\n",
    "    return list(\n",
    "        map(lambda nn_annotation: nn_annotation.metadata['word'], nn_annotations)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|nn_tokens|\n",
      "+---------+\n",
      "|[person] |\n",
      "|[life]   |\n",
      "|[]       |\n",
      "|[car]    |\n",
      "|[]       |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(map_annotations(nn_tokens, ArrayType(StringType()))('pos').alias('nn_tokens')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
