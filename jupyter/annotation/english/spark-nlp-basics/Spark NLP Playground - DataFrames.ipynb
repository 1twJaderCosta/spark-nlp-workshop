{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = DocumentAssembler().setInputCol('text').setOutputCol('document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCols('document').setOutputCol('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pos = PerceptronModel.pretrained().setInputCols('document', 'token').setOutputCol('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([document, tokenizer, pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.text('/Users/saifa/sample-sentences-en.txt').toDF('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|         Chapter 1 .|\n",
      "|Once when I was s...|\n",
      "|It was a picture ...|\n",
      "|Here is a copy of...|\n",
      "|In the book it sa...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|               token|                 pos|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|         Chapter 1 .|[[document, 0, 10...|[[token, 0, 6, Ch...|[[pos, 0, 6, NN, ...|\n",
      "|Once when I was s...|[[document, 0, 13...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|\n",
      "|It was a picture ...|[[document, 0, 73...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|\n",
      "|Here is a copy of...|[[document, 0, 30...|[[token, 0, 3, He...|[[pos, 0, 3, RB, ...|\n",
      "|In the book it sa...|[[document, 0, 87...|[[token, 0, 1, In...|[[pos, 0, 1, IN, ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored = result\\\n",
    "  .select('text', 'pos.begin', 'pos.end', 'pos.result', 'pos.metadata')\\\n",
    "  .toDF('text', 'pos_begin', 'pos_end', 'pos_result', 'pos_meta')\\\n",
    "  .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- pos_begin: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- pos_end: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- pos_result: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- pos_meta: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|           pos_begin|             pos_end|          pos_result|            pos_meta|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         Chapter 1 .|          [0, 8, 10]|          [6, 8, 10]|         [NN, CD, .]|[[word -> Chapter...|\n",
      "|Once when I was s...|[0, 5, 10, 12, 16...|[3, 8, 10, 14, 18...|[RB, WRB, PRP, VB...|[[word -> Once], ...|\n",
      "|It was a picture ...|[0, 3, 7, 9, 17, ...|[1, 5, 7, 15, 18,...|[PRP, VBD, DT, NN...|[[word -> It], [w...|\n",
      "|Here is a copy of...|[0, 5, 8, 10, 15,...|[3, 6, 8, 13, 16,...|[RB, VBZ, DT, NN,...|[[word -> Here], ...|\n",
      "|In the book it sa...|[0, 3, 7, 12, 15,...|[1, 5, 10, 13, 18...|[IN, DT, NN, PRP,...|[[word -> In], [w...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "## Spark SQL Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|           pos_begin|             pos_end|          pos_result|            pos_meta|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Once when I was s...|[0, 5, 10, 12, 16...|[3, 8, 10, 14, 18...|[RB, WRB, PRP, VB...|[[word -> Once], ...|\n",
      "|It was a picture ...|[0, 3, 7, 9, 17, ...|[1, 5, 7, 15, 18,...|[PRP, VBD, DT, NN...|[[word -> It], [w...|\n",
      "|In the book it sa...|[0, 3, 7, 12, 15,...|[1, 5, 10, 13, 18...|[IN, DT, NN, PRP,...|[[word -> In], [w...|\n",
      "|And after some wo...|[0, 4, 10, 15, 20...|[2, 8, 13, 18, 23...|[CC, IN, DT, NN, ...|[[word -> And], [...|\n",
      "|It looked like th...|[0, 3, 10, 15, 20...|[1, 8, 13, 18, 20...|[PRP, VBD, IN, DT...|[[word -> It], [w...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.filter(array_contains('pos_result', 'VBD')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          pos_result|token_count|\n",
      "+--------------------+-----------+\n",
      "|         [NN, CD, .]|          3|\n",
      "|[RB, WRB, PRP, VB...|         27|\n",
      "|[PRP, VBD, DT, NN...|         16|\n",
      "|[RB, VBZ, DT, NN,...|          8|\n",
      "|[IN, DT, NN, PRP,...|         18|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.withColumn('token_count', size('pos_result')).select('pos_result', 'token_count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                text|array_max(pos_end)|\n",
      "+--------------------+------------------+\n",
      "|         Chapter 1 .|                10|\n",
      "|Once when I was s...|               130|\n",
      "|It was a picture ...|                73|\n",
      "|Here is a copy of...|                30|\n",
      "|In the book it sa...|                87|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.select('text', array_max('pos_end')).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          pos_result|          unique_pos|\n",
      "+--------------------+--------------------+\n",
      "|         [NN, CD, .]|         [NN, CD, .]|\n",
      "|[RB, WRB, PRP, VB...|[RB, WRB, PRP, VB...|\n",
      "|[PRP, VBD, DT, NN...|[PRP, VBD, DT, NN...|\n",
      "|[RB, VBZ, DT, NN,...|[RB, VBZ, DT, NN,...|\n",
      "|[IN, DT, NN, PRP,...|[IN, DT, NN, PRP,...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.withColumn('unique_pos', array_distinct('pos_result')).select('pos_result', 'unique_pos').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-----+\n",
      "|array_sort(array_distinct(pos_result))|count|\n",
      "+--------------------------------------+-----+\n",
      "|                  [,, ., CC, DT, IN...|    1|\n",
      "|                  [,, -, ., :, CC, ...|    1|\n",
      "|                  ['', ., :, DT, PR...|    1|\n",
      "|                  [,, ., CD, DT, IN...|    1|\n",
      "|                          ['', ., WRB]|    1|\n",
      "|                  [(, ), ,, ., CC, ...|    1|\n",
      "|                  [., NNS, PRP, RB,...|    1|\n",
      "|                  ['', ,, ., DT, IN...|    1|\n",
      "|                           [., CD, NN]|    2|\n",
      "|                  [,, ., DT, IN, JJ...|    1|\n",
      "+--------------------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.groupBy(array_sort(array_distinct('pos_result'))).count().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "### SQL Functions with `col`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|pos_meta[0][word]|\n",
      "+-----------------+\n",
      "|          Chapter|\n",
      "|             Once|\n",
      "|               It|\n",
      "|             Here|\n",
      "|               In|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stored.select(col('pos_meta').getItem(0).getItem('word')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Spark NLP Annotation UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|pos                                                                                                          |\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "|[[pos, 0, 6, NN, [word -> Chapter], []], [pos, 8, 8, CD, [word -> 1], []], [pos, 10, 10, ., [word -> .], []]]|\n",
      "+-------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('pos').show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_tokens(annotations):\n",
    "    nn_annotations = list(\n",
    "        filter(lambda annotation: annotation.result == 'NN', annotations)\n",
    "    )\n",
    "    return list(\n",
    "        map(lambda nn_annotation: nn_annotation.metadata['word'], nn_annotations)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+\n",
      "|nn_tokens                                                |\n",
      "+---------------------------------------------------------+\n",
      "|[Chapter]                                                |\n",
      "|[picture, book, primeval, forest]                        |\n",
      "|[picture, boa, constrictor, act, animal]                 |\n",
      "|[copy]                                                   |\n",
      "|[book, whole]                                            |\n",
      "|[digestion]                                              |\n",
      "|[jungle]                                                 |\n",
      "|[work, pencil, drawing]                                  |\n",
      "|[]                                                       |\n",
      "|[masterpiece, grown]                                     |\n",
      "|[]                                                       |\n",
      "|[hat]                                                    |\n",
      "|[picture, hat]                                           |\n",
      "|[picture, boa, constrictor, elephant]                    |\n",
      "|[grown, boa, constrictor, grown]                         |\n",
      "|[]                                                       |\n",
      "|[grown, response, time, boa, geography, history, grammar]|\n",
      "|[age, career, painter]                                   |\n",
      "|[failure]                                                |\n",
      "|[anything]                                               |\n",
      "+---------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(map_annotations(nn_tokens, ArrayType(StringType()))('pos').alias('nn_tokens')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
