{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nlp.johnsnowlabs.com/assets/images/logo.png\" width=\"180\" height=\"50\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vivekn Sentiment Analysis\n",
    "\n",
    "In the following example, we walk-through Sentiment Analysis training and prediction using Spark NLP Annotators.\n",
    "\n",
    "The ViveknSentimentApproach annotator will compute [Vivek Narayanan algorithm](https://arxiv.org/pdf/1305.6143.pdf) with either a column in training dataset with rows labelled 'positive' or 'negative' or a folder full of positive text and a folder with negative text. Using n-grams and negation of sequences, this statistical model can achieve high accuracy if trained properly.\n",
    "\n",
    "Spark can be leveraged in training by utilizing ReadAs.Dataset setting. Spark will be used during prediction by default.\n",
    "\n",
    "We also include in this pipeline a spell checker which shall correct our sentences for better Sentiment Analysis accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Call necessary imports and set the resource path to read local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import array_contains,when\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load SparkSession if not already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.3.4\n",
      "Apache Spark version:  2.4.3\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-16 21:58:13--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt\n",
      "R'esolution de s3.amazonaws.com (s3.amazonaws.com)... 52.216.200.5\n",
      "Connexion `a s3.amazonaws.com (s3.amazonaws.com)|52.216.200.5|:443... connect'e.\n",
      "requ^ete HTTP transmise, en attente de la r'eponse... 304 Not Modified\n",
      "Le fichier << /tmp/words.txt >> n'a pas 'et'e modifier sur le serveur. T'el'echargement saut'e.\n",
      "\n",
      "--2019-07-16 21:58:14--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip\n",
      "R'esolution de s3.amazonaws.com (s3.amazonaws.com)... 52.216.200.5\n",
      "Connexion `a s3.amazonaws.com (s3.amazonaws.com)|52.216.200.5|:443... connect'e.\n",
      "requ^ete HTTP transmise, en attente de la r'eponse... 304 Not Modified\n",
      "Le fichier << /tmp/sentiment.parquet.zip >> n'a pas 'et'e modifier sur le serveur. T'el'echargement saut'e.\n",
      "\n",
      "Archive:  /tmp/sentiment.parquet.zip\n",
      "   creating: /tmp/sentiment.parquet/\n",
      "  inflating: /tmp/sentiment.parquet/.part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00002-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      " extracting: /tmp/sentiment.parquet/_SUCCESS  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00003-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n",
      "  inflating: /tmp/sentiment.parquet/part-00000-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet  \n",
      "  inflating: /tmp/sentiment.parquet/.part-00001-08092d15-dd8c-40f9-a1df-641a1a4b1698.snappy.parquet.crc  \n"
     ]
    }
   ],
   "source": [
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/spell/words.txt -P /tmp\n",
    "!rm -rf /tmp/sentiment.parquet\n",
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment.parquet.zip -P /tmp\n",
    "! unzip /tmp/sentiment.parquet.zip -d /tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3. Load a spark dataset and put it in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+---------------+\n",
      "|itemid|sentiment|                text|sentiment_label|\n",
      "+------+---------+--------------------+---------------+\n",
      "|799033|        0|@FrankomQ8 What's...|       negative|\n",
      "|799034|        1|@FranKoUK guitar ...|       positive|\n",
      "|799035|        0|@frankparenteau u...|       negative|\n",
      "|799036|        1|@frankparenteau w...|       positive|\n",
      "|799037|        1|@FrankPatris dude...|       positive|\n",
      "|799038|        0|@FrankRamblings a...|       negative|\n",
      "|799039|        1|@frankroberts  ni...|       positive|\n",
      "|799040|        0|@frankroberts ur ...|       negative|\n",
      "|799041|        1|@FrankS Breaking ...|       positive|\n",
      "|799042|        1|@frankschultelad ...|       positive|\n",
      "|799043|        0|@frankshorter Wol...|       negative|\n",
      "|799044|        0|@franksting - its...|       negative|\n",
      "|799045|        1|@franksting Ha! D...|       positive|\n",
      "|799046|        1|@franksting yeah,...|       positive|\n",
      "|799047|        1|@franksting yes, ...|       positive|\n",
      "|799048|        1|@FrankSylar arn't...|       positive|\n",
      "|799049|        1|    @frankules WO ? |       positive|\n",
      "|799050|        0|@frankwkelly I'm ...|       negative|\n",
      "|799051|        1|@FrankXSalinas Th...|       positive|\n",
      "|799052|        1|@frankybhoy93 tha...|       positive|\n",
      "+------+---------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load the input data to be annotated\n",
    "#We change 0 and 1 with negative and positive\n",
    "data = spark. \\\n",
    "        read. \\\n",
    "        parquet(\"/tmp/sentiment.parquet\"). \\\n",
    "        withColumn(\"sentiment_label\", when(col(\"sentiment\") == 0, \"negative\").otherwise(\"positive\")). \\\n",
    "        limit(1000).cache()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create the document assembler, which will put target text column into Annotation form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the dataframe\n",
    "document_assembler = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\")\\\n",
    "            .setOutputCol(\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+---------------+--------------------+\n",
      "|itemid|sentiment|                text|sentiment_label|            document|\n",
      "+------+---------+--------------------+---------------+--------------------+\n",
      "|799033|        0|@FrankomQ8 What's...|       negative|[[document, 0, 37...|\n",
      "|799034|        1|@FranKoUK guitar ...|       positive|[[document, 0, 48...|\n",
      "|799035|        0|@frankparenteau u...|       negative|[[document, 0, 11...|\n",
      "|799036|        1|@frankparenteau w...|       positive|[[document, 0, 78...|\n",
      "|799037|        1|@FrankPatris dude...|       positive|[[document, 0, 74...|\n",
      "+------+---------+--------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example: Checkout the output of document assembler\n",
    "assembled = document_assembler.transform(data)\n",
    "assembled.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create Sentence detector to parse sub sentences in every document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentence detector\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+---------------+--------------------+--------------------+\n",
      "|itemid|sentiment|                text|sentiment_label|            document|            sentence|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+\n",
      "|799033|        0|@FrankomQ8 What's...|       negative|[[document, 0, 37...|[[document, 0, 23...|\n",
      "|799034|        1|@FranKoUK guitar ...|       positive|[[document, 0, 48...|[[document, 0, 44...|\n",
      "|799035|        0|@frankparenteau u...|       negative|[[document, 0, 11...|[[document, 0, 36...|\n",
      "|799036|        1|@frankparenteau w...|       positive|[[document, 0, 78...|[[document, 0, 71...|\n",
      "|799037|        1|@FrankPatris dude...|       positive|[[document, 0, 74...|[[document, 0, 35...|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example: Checkout the output of sentence detector\n",
    "sentence_data = sentence_detector.transform(assembled)\n",
    "sentence_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. The tokenizer will match standard tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenizer\n",
    "tokenizer = Tokenizer() \\\n",
    "            .setInputCols([\"sentence\"]) \\\n",
    "            .setOutputCol(\"token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|itemid|sentiment|                text|sentiment_label|            document|            sentence|               token|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "|799033|        0|@FrankomQ8 What's...|       negative|[[document, 0, 37...|[[document, 0, 23...|[[token, 0, 9, @F...|\n",
      "|799034|        1|@FranKoUK guitar ...|       positive|[[document, 0, 48...|[[document, 0, 44...|[[token, 0, 8, @F...|\n",
      "|799035|        0|@frankparenteau u...|       negative|[[document, 0, 11...|[[document, 0, 36...|[[token, 0, 14, @...|\n",
      "|799036|        1|@frankparenteau w...|       positive|[[document, 0, 78...|[[document, 0, 71...|[[token, 0, 14, @...|\n",
      "|799037|        1|@FrankPatris dude...|       positive|[[document, 0, 74...|[[document, 0, 35...|[[token, 0, 11, @...|\n",
      "+------+---------+--------------------+---------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Example: Checkout the outout of tokenizer\n",
    "tokenized = tokenizer.fit(sentence_data).transform(sentence_data)\n",
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Normalizer will clean out the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer() \\\n",
    "            .setInputCols([\"token\"]) \\\n",
    "            .setOutputCol(\"normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. The spell checker will correct normalized tokens, this trains with a dictionary of english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Spell Checker\n",
    "spell_checker = NorvigSweetingApproach() \\\n",
    "            .setInputCols([\"normal\"]) \\\n",
    "            .setOutputCol(\"spell\") \\\n",
    "            .setDictionary(\"/tmp/words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Create the ViveknSentimentApproach and set resources to train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_detector = ViveknSentimentApproach() \\\n",
    "    .setInputCols([\"spell\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment\") \\\n",
    "    .setSentimentCol(\"sentiment_label\") \\\n",
    "    .setPruneCorpus(0) \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. The finisher will utilize sentiment analysis output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"sentiment\"]) \\\n",
    "    .setIncludeMetadata(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Fit and predict over data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed pipeline process: 5.5167460441589355\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    normalizer,\n",
    "    spell_checker,\n",
    "    sentiment_detector,\n",
    "    finisher\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "sentiment_data = pipeline.fit(data).transform(data)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time elapsed pipeline process: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------------------------------------------------------------------------------------------+---------------+--------------------+\n",
      "|itemid|text                                                                                                             |sentiment_label|finished_sentiment  |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------+---------------+--------------------+\n",
      "|799033|@FrankomQ8 What's in it? I'm starving                                                                            |negative       |[negative, negative]|\n",
      "|799034|@FranKoUK guitar lessons soundsss good  when?  xx                                                                |positive       |[positive, positive]|\n",
      "|799035|@frankparenteau used and abused, huh? i do feel like that sometimes, especially when clients ignore my invoices. |negative       |[negative, negative]|\n",
      "|799036|@frankparenteau well, with itunes he gets more hits w/o promo, probably. eh...                                   |positive       |[positive, positive]|\n",
      "|799037|@FrankPatris dude have you season 5? i finished 16 eoisodes of season 4 na                                       |positive       |[positive, positive]|\n",
      "+------+-----------------------------------------------------------------------------------------------------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_data.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@FrankomQ8 What's in it? I'm starving -> ['negative', 'negative']\n",
      "@frankparenteau used and abused, huh? i do feel like that sometimes, especially when clients ignore my invoices. -> ['negative', 'negative']\n",
      "@FrankRamblings and I CAN listen to them on Itunes, so it's not a corrupted file problem -> ['negative']\n",
      "@frankroberts ur on top of ur twitter game! thanks hun. like you, I wish I updated more. Dig your writings as well. Sad news RE: Octavia -> ['negative', 'negative', 'negative', 'negative', 'negative']\n",
      "@frankshorter Wolfram cant do 3900000000000000-3800000000000000 -> ['negative']\n"
     ]
    }
   ],
   "source": [
    "# Negative Sentiments\n",
    "for r in sentiment_data.where(array_contains(sentiment_data.finished_sentiment, \"negative\")).take(5):\n",
    "    print(r['text'].strip(),\"->\",r['finished_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@FranKoUK guitar lessons soundsss good  when?  xx -> ['positive', 'positive']\n",
      "@frankparenteau well, with itunes he gets more hits w/o promo, probably. eh... -> ['positive', 'positive']\n",
      "@FrankPatris dude have you season 5? i finished 16 eoisodes of season 4 na -> ['positive', 'positive']\n",
      "@frankroberts  nice.  this has happened to me like 20 times. lol.  pace yourself. -> ['positive', 'positive', 'positive', 'positive']\n",
      "@FrankS Breaking Bad: eher Drama mit Comedy, Entourage: Single Camera Comedy, muss man auf jeden Fall gesehen haben -> ['positive']\n"
     ]
    }
   ],
   "source": [
    "# Positive Sentiments\n",
    "for r in sentiment_data.where(array_contains(sentiment_data.finished_sentiment, \"positive\")).take(5):\n",
    "    print(r['text'].strip(),\"->\",r['finished_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
