{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please make sure you have SparkNLP 2.4.1 and SparkNLP Enterprise 2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "import pyspark.sql.functions as F\n",
    "#from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import StringIndexerModel\n",
    "from pyspark.ml.classification import OneVsRestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = concepts = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"../../../data/resolution/snomed_sample.csv\")\\\n",
    ".withColumn(\"term\", F.expr(\"lower(term)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_chars = [\"'\",\",\",\"/\",\" \",\".\",\"|\",\"@\",\"#\",\"%\",\"&\",\"$\",\"[\",\"]\",\"(\",\")\",\"-\",\";\",\"=\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docAssembler = DocumentAssembler().setInputCol(\"term\").setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer().setInputCols(\"document\").setOutputCol(\"token\")\\\n",
    "    .setSplitChars(tokenizer_chars)\n",
    "\n",
    "pipelineModel = Pipeline().setStages([docAssembler, tokenizer]).fit(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embeddingsModel = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"document\", \"token\")\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2Chunk = Doc2Chunk().setInputCols(\"document\").setOutputCol(\"chunk\")\n",
    "\n",
    "chunkEmbeddings = ChunkEmbeddings()\\\n",
    "    .setInputCols(\"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"chunk_embeddings\")\n",
    "\n",
    "pipelineChunkEmbeddings = PipelineModel([doc2Chunk, chunkEmbeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_embedded = PipelineModel([pipelineModel, embeddingsModel, pipelineChunkEmbeddings]).transform(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_embedded.write.mode(\"overwrite\").save(\"data/concepts_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts_embedded = spark.read.load(\"data/concepts_embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9727644122164317"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check embeddings coverage\n",
    "concepts_embedded.selectExpr(\"conceptId\",\"explode(embeddings) as embs\")\\\n",
    ".selectExpr(\"conceptId\",\"case when embs.metadata.isOOV=='false' then 1 else 0 end as coverage\")\\\n",
    ".groupby(\"conceptId\").agg(F.expr(\"avg(coverage) as cov\")).orderBy(\"cov\").toPandas()[\"cov\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_distribution = concepts_embedded.selectExpr(\"explode(token.result) as word\").groupby(\"word\").count()\n",
    "#word_distribution.orderBy(\"count\",ascending=True).show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_distribution.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resolve_snomed_clinical_l1 download started this may take some time.\n",
      "Approximate size to download 15.3 MB\n",
      "[OK!]\n",
      "resolve_snomed_clinical_l2 download started this may take some time.\n",
      "Approx size to download 583.4 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChunkEntityResolverSelector_d41a7a88595b"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SNOMED Resolution\n",
    "snomed_resolver_l1 = DocumentLogRegClassifierModel.pretrained(\"resolve_snomed_clinical_l1\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"token\").setOutputCol(\"partition\")\n",
    "snomed_resolver_l2 = ResourceDownloader.downloadPipeline(\"resolve_snomed_clinical_l2\", \"en\", \"clinical/models\")\n",
    "snomed_resolver_l2.stages[-1].setInputCols(\"partition\",\"token\",\"chunk_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "snomed_resolution = PipelineModel([snomed_resolver_l1, RecursivePipelineModel(snomed_resolver_l2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "transformed_full = snomed_resolution.transform(concepts_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = transformed_full.withColumn(\"prediction\", F.expr(\"partition.result[0]\")).cache()\n",
    "metrics = predicted.withColumn(\"ok\",F.expr(\"case when prediction==topTerm then 1 else 0 end\"))\\\n",
    "                                   .groupby(\"topTerm\").agg(F.expr(\"avg(ok) as recall\"), F.expr(\"count(ok) as tr_cnt\"))\\\n",
    "                                    .join(\n",
    "predicted.withColumn(\"ok\",F.expr(\"case when prediction==topTerm then 1 else 0 end\"))\\\n",
    "                                   .groupby(\"prediction\").agg(F.expr(\"avg(ok) as precision\")),F.col(\"topTerm\")==F.col(\"prediction\")\n",
    ").withColumn(\"f1\", F.expr(\"2*precision*recall/(precision+recall)\")).orderBy(\"f1\")\\\n",
    ".selectExpr(\"topTerm\",\"tr_cnt\",\"round(precision,3) as train_precision\",\"round(recall,3) as train_recall\",\"round(f1, 3) as train_f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_alternatives = predicted\\\n",
    "    .withColumn(\"resolution\",F.expr(\"split(substring(snomed_code.metadata[0]['all_k_results'],2,length(snomed_code.metadata[0]['all_k_results'])-2),'\\\\\\\\],\\\\\\\\[')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaled = with_alternatives\\\n",
    "    .withColumn(\"good\", F.expr(\"case when conceptId=snomed_code.result[0] then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat5\", F.expr(\"case when array_contains(slice(resolution, 1, 5), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat10\", F.expr(\"case when array_contains(slice(resolution, 1, 10), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat20\", F.expr(\"case when array_contains(slice(resolution, 1, 20), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat30\", F.expr(\"case when array_contains(slice(resolution, 1, 30), conceptId) then 1 else 0 end\"))\\\n",
    "    .withColumn(\"hat500\", F.expr(\"case when array_contains(slice(resolution, 1, 500), conceptId) then 1 else 0 end\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaled.groupby(\"topTerm\").agg(\n",
    "    F.mean(\"good\"), \n",
    "    F.mean(\"hat5\"), \n",
    "    F.mean(\"hat10\"), \n",
    "    F.mean(\"hat20\"), \n",
    "    F.mean(\"hat30\"), \n",
    "    F.mean(\"hat500\"), \n",
    "    F.count(\"good\")).orderBy(\"count(good)\", ascending=False)\\\n",
    ".selectExpr(\"topTerm\",\n",
    "            \"round(`avg(good)`, 2) as good\",\n",
    "            \"round(`avg(hat5)`, 2) as hat5\",\n",
    "            \"round(`avg(hat10)`, 2) as hat10\",\n",
    "            \"round(`avg(hat20)`, 2) as hat20\",\n",
    "            \"round(`avg(hat30)`, 2) as hat30\",\n",
    "            \"round(`avg(hat500)`, 2) as hat500\",\n",
    "            \"`count(good)` as total\")\\\n",
    ".show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round((time.time()-start)/60, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsl368",
   "language": "python",
   "name": "jsl368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
